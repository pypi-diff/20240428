# Comparing `tmp/gym_jiminy-1.8.4-py3-none-any.whl.zip` & `tmp/gym_jiminy-1.8.5-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,37 +1,37 @@
-Zip file size: 116825 bytes, number of entries: 35
--rw-r--r--  2.0 unx      230 b- defN 24-Apr-19 21:51 gym_jiminy/common/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 24-Apr-19 21:51 gym_jiminy/common/py.typed
--rw-r--r--  2.0 unx     1495 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/__init__.py
--rw-r--r--  2.0 unx    10466 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/blocks.py
--rw-r--r--  2.0 unx    14577 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/interfaces.py
--rw-r--r--  2.0 unx    40682 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/pipeline.py
--rw-r--r--  2.0 unx    18035 b- defN 24-Apr-19 21:51 gym_jiminy/common/bases/quantity.py
--rw-r--r--  2.0 unx      385 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/__init__.py
--rw-r--r--  2.0 unx    37430 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/deformation_estimator.py
--rw-r--r--  2.0 unx    17212 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/mahony_filter.py
--rw-r--r--  2.0 unx    10089 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/motor_safety_limit.py
--rw-r--r--  2.0 unx    26392 b- defN 24-Apr-19 21:51 gym_jiminy/common/blocks/proportional_derivative_controller.py
--rw-r--r--  2.0 unx      178 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/__init__.py
--rw-r--r--  2.0 unx    69411 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/generic.py
--rw-r--r--  2.0 unx    18748 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/locomotion.py
--rw-r--r--  2.0 unx      118 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/internal/__init__.py
--rw-r--r--  2.0 unx     9350 b- defN 24-Apr-19 21:51 gym_jiminy/common/envs/internal/play.py
--rw-r--r--  2.0 unx      367 b- defN 24-Apr-19 21:51 gym_jiminy/common/quantities/__init__.py
--rw-r--r--  2.0 unx    11600 b- defN 24-Apr-19 21:51 gym_jiminy/common/quantities/generic.py
--rw-r--r--  2.0 unx     4496 b- defN 24-Apr-19 21:51 gym_jiminy/common/quantities/locomotion.py
--rw-r--r--  2.0 unx     7024 b- defN 24-Apr-19 21:51 gym_jiminy/common/quantities/manager.py
--rw-r--r--  2.0 unx     2263 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/__init__.py
--rw-r--r--  2.0 unx    21000 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/math.py
--rw-r--r--  2.0 unx     8972 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/misc.py
--rw-r--r--  2.0 unx    10189 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/pipeline.py
--rw-r--r--  2.0 unx    53495 b- defN 24-Apr-19 21:51 gym_jiminy/common/utils/spaces.py
--rw-r--r--  2.0 unx      477 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/__init__.py
--rw-r--r--  2.0 unx     6115 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/flatten.py
--rw-r--r--  2.0 unx     4039 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/normalize.py
--rw-r--r--  2.0 unx     3747 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/observation_filter.py
--rw-r--r--  2.0 unx    10626 b- defN 24-Apr-19 21:51 gym_jiminy/common/wrappers/observation_stack.py
--rw-r--r--  2.0 unx     1605 b- defN 24-Apr-19 21:52 gym_jiminy-1.8.4.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-19 21:52 gym_jiminy-1.8.4.dist-info/WHEEL
--rw-r--r--  2.0 unx       11 b- defN 24-Apr-19 21:52 gym_jiminy-1.8.4.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     3266 b- defN 24-Apr-19 21:52 gym_jiminy-1.8.4.dist-info/RECORD
-35 files, 424182 bytes uncompressed, 111497 bytes compressed:  73.7%
+Zip file size: 119096 bytes, number of entries: 35
+-rw-r--r--  2.0 unx      230 b- defN 24-Apr-28 20:51 gym_jiminy/common/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 24-Apr-28 20:51 gym_jiminy/common/py.typed
+-rw-r--r--  2.0 unx     1548 b- defN 24-Apr-28 20:51 gym_jiminy/common/bases/__init__.py
+-rw-r--r--  2.0 unx    10466 b- defN 24-Apr-28 20:51 gym_jiminy/common/bases/blocks.py
+-rw-r--r--  2.0 unx    14953 b- defN 24-Apr-28 20:51 gym_jiminy/common/bases/interfaces.py
+-rw-r--r--  2.0 unx    40957 b- defN 24-Apr-28 20:51 gym_jiminy/common/bases/pipeline.py
+-rw-r--r--  2.0 unx    18035 b- defN 24-Apr-28 20:51 gym_jiminy/common/bases/quantity.py
+-rw-r--r--  2.0 unx      385 b- defN 24-Apr-28 20:51 gym_jiminy/common/blocks/__init__.py
+-rw-r--r--  2.0 unx    37430 b- defN 24-Apr-28 20:51 gym_jiminy/common/blocks/deformation_estimator.py
+-rw-r--r--  2.0 unx    17212 b- defN 24-Apr-28 20:51 gym_jiminy/common/blocks/mahony_filter.py
+-rw-r--r--  2.0 unx    10089 b- defN 24-Apr-28 20:51 gym_jiminy/common/blocks/motor_safety_limit.py
+-rw-r--r--  2.0 unx    26459 b- defN 24-Apr-28 20:51 gym_jiminy/common/blocks/proportional_derivative_controller.py
+-rw-r--r--  2.0 unx      178 b- defN 24-Apr-28 20:51 gym_jiminy/common/envs/__init__.py
+-rw-r--r--  2.0 unx    70853 b- defN 24-Apr-28 20:51 gym_jiminy/common/envs/generic.py
+-rw-r--r--  2.0 unx    18748 b- defN 24-Apr-28 20:51 gym_jiminy/common/envs/locomotion.py
+-rw-r--r--  2.0 unx      118 b- defN 24-Apr-28 20:51 gym_jiminy/common/envs/internal/__init__.py
+-rw-r--r--  2.0 unx     9350 b- defN 24-Apr-28 20:51 gym_jiminy/common/envs/internal/play.py
+-rw-r--r--  2.0 unx      367 b- defN 24-Apr-28 20:51 gym_jiminy/common/quantities/__init__.py
+-rw-r--r--  2.0 unx    11998 b- defN 24-Apr-28 20:51 gym_jiminy/common/quantities/generic.py
+-rw-r--r--  2.0 unx     4496 b- defN 24-Apr-28 20:51 gym_jiminy/common/quantities/locomotion.py
+-rw-r--r--  2.0 unx     7024 b- defN 24-Apr-28 20:51 gym_jiminy/common/quantities/manager.py
+-rw-r--r--  2.0 unx     2318 b- defN 24-Apr-28 20:51 gym_jiminy/common/utils/__init__.py
+-rw-r--r--  2.0 unx    21000 b- defN 24-Apr-28 20:51 gym_jiminy/common/utils/math.py
+-rw-r--r--  2.0 unx     8920 b- defN 24-Apr-28 20:51 gym_jiminy/common/utils/misc.py
+-rw-r--r--  2.0 unx    10189 b- defN 24-Apr-28 20:51 gym_jiminy/common/utils/pipeline.py
+-rw-r--r--  2.0 unx    54010 b- defN 24-Apr-28 20:51 gym_jiminy/common/utils/spaces.py
+-rw-r--r--  2.0 unx      421 b- defN 24-Apr-28 20:51 gym_jiminy/common/wrappers/__init__.py
+-rw-r--r--  2.0 unx     6153 b- defN 24-Apr-28 20:51 gym_jiminy/common/wrappers/flatten.py
+-rw-r--r--  2.0 unx     4039 b- defN 24-Apr-28 20:51 gym_jiminy/common/wrappers/normalize.py
+-rw-r--r--  2.0 unx     7770 b- defN 24-Apr-28 20:51 gym_jiminy/common/wrappers/observation_filter.py
+-rw-r--r--  2.0 unx    10955 b- defN 24-Apr-28 20:51 gym_jiminy/common/wrappers/observation_stack.py
+-rw-r--r--  2.0 unx     1605 b- defN 24-Apr-28 20:52 gym_jiminy-1.8.5.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-28 20:52 gym_jiminy-1.8.5.dist-info/WHEEL
+-rw-r--r--  2.0 unx       11 b- defN 24-Apr-28 20:52 gym_jiminy-1.8.5.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     3266 b- defN 24-Apr-28 20:52 gym_jiminy-1.8.5.dist-info/RECORD
+35 files, 431645 bytes uncompressed, 113768 bytes compressed:  73.6%
```

## zipnote {}

```diff
@@ -87,20 +87,20 @@
 
 Filename: gym_jiminy/common/wrappers/observation_filter.py
 Comment: 
 
 Filename: gym_jiminy/common/wrappers/observation_stack.py
 Comment: 
 
-Filename: gym_jiminy-1.8.4.dist-info/METADATA
+Filename: gym_jiminy-1.8.5.dist-info/METADATA
 Comment: 
 
-Filename: gym_jiminy-1.8.4.dist-info/WHEEL
+Filename: gym_jiminy-1.8.5.dist-info/WHEEL
 Comment: 
 
-Filename: gym_jiminy-1.8.4.dist-info/top_level.txt
+Filename: gym_jiminy-1.8.5.dist-info/top_level.txt
 Comment: 
 
-Filename: gym_jiminy-1.8.4.dist-info/RECORD
+Filename: gym_jiminy-1.8.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## gym_jiminy/common/bases/__init__.py

```diff
@@ -14,27 +14,29 @@
                          InterfaceObserver,
                          InterfaceController,
                          InterfaceJiminyEnv)
 from .blocks import (BlockStateT,
                      InterfaceBlock,
                      BaseObserverBlock,
                      BaseControllerBlock)
-from .pipeline import (BasePipelineWrapper,
+from .pipeline import (NestedObsT,
+                       BasePipelineWrapper,
                        BaseTransformObservation,
                        BaseTransformAction,
                        ObservedJiminyEnv,
                        ControlledJiminyEnv)
 
 
 __all__ = [
     'SharedCache',
     'QuantityCreator',
     'AbstractQuantity',
     'DT_EPS',
     'ObsT',
+    'NestedObsT',
     'ActT',
     'BaseObsT',
     'BaseActT',
     'BlockStateT',
     'InfoType',
     'SensorMeasurementStackMap',
     'EngineObsType',
```

## gym_jiminy/common/bases/interfaces.py

```diff
@@ -1,15 +1,15 @@
 """Controller and observer abstract interfaces from reinforcement learning,
 specifically design for Jiminy engine, and defined as mixin classes. Any
 observer/controller block must inherit and implement those interfaces.
 """
 from abc import abstractmethod, ABC
 from collections import OrderedDict
-from typing import Dict, Any, TypeVar, Generic, no_type_check, TYPE_CHECKING
-from typing_extensions import TypeAlias
+from typing import (
+    Dict, Any, TypeVar, Generic, no_type_check, TypedDict, TYPE_CHECKING)
 
 import numpy as np
 import numpy.typing as npt
 import gymnasium as gym
 
 import jiminy_py.core as jiminy
 from jiminy_py.simulator import Simulator
@@ -29,21 +29,30 @@
 BaseObsT = TypeVar('BaseObsT', bound=DataNested)
 BaseActT = TypeVar('BaseActT', bound=DataNested)
 
 SensorMeasurementStackMap = Dict[str, npt.NDArray[np.float64]]
 InfoType = Dict[str, Any]
 
 
-# class EngineObsType(TypedDict):
-#     t: np.ndarray
-#     state:  DataNested
-#     features: DataNested
-
-
-EngineObsType: TypeAlias = DataNested
+class EngineObsType(TypedDict):
+    """Raw observation provided by Jiminy Core Engine prior to any
+    post-processing.
+    """
+    t: np.ndarray
+    """Current simulation time.
+    """
+    states: Dict[str, DataNested]
+    """State of the agent.
+    """
+    measurements: SensorMeasurementStackMap
+    """Sensor measurements. Individual data for each sensor are aggregated by
+    types in 2D arrays whose first dimension gathers the measured components
+    and second dimension corresponds to individual measurements sorted by
+    sensor indices.
+    """
 
 
 class InterfaceObserver(ABC, Generic[ObsT, BaseObsT]):
     """Observer interface for both observers and environments.
     """
     observe_dt: float = -1
     observation_space: gym.Space  # [ObsT]
@@ -193,15 +202,15 @@
         # Track whether the observation has been refreshed manually since the
         # last called '_controller_handle'. It typically happens at the end of
         # every simulation step to return an observation that is consistent
         # with the updated state of the agent.
         self.__is_observation_refreshed = True
 
         # Store latest engine measurement for efficiency
-        self.__measurement: EngineObsType = OrderedDict(
+        self.__measurement = EngineObsType(
             t=np.array(0.0),
             states=OrderedDict(
                 agent=OrderedDict(q=np.array([]), v=np.array([]))),
             measurements=OrderedDict(self.robot.sensor_measurements))
         self._sensors_types = tuple(self.robot.sensor_measurements.keys())
 
         # Call super to allow mixing interfaces through multiple inheritance
@@ -256,15 +265,15 @@
             sensor_measurements_it = iter(sensor_measurements.values())
             for sensor_type in self._sensors_types:
                 measurement_sensors[sensor_type] = next(sensor_measurements_it)
             try:
                 self.refresh_observation(measurement)
             except RuntimeError as e:
                 raise RuntimeError(
-                    "The observation space must be constant.") from e
+                    "The observation space must be invariant.") from e
             self.__is_observation_refreshed = True
 
     def _controller_handle(self,
                            t: float,
                            q: np.ndarray,
                            v: np.ndarray,
                            sensor_measurements: jiminy.SensorMeasurementTree,
```

## gym_jiminy/common/bases/pipeline.py

```diff
@@ -105,14 +105,24 @@
 
         It is mainly used by autocomplete feature of Ipython. It is overloaded
         to get consistent autocompletion wrt `getattr`.
         """
         return [*super().__dir__(), *dir(self.env)]
 
     @property
+    def render_mode(self) -> Optional[str]:
+        """Rendering mode of the base environment.
+        """
+        return self.env.render_mode
+
+    @render_mode.setter
+    def render_mode(self, render_mode: str) -> None:
+        self.env.render_mode = render_mode
+
+    @property
     def spec(self) -> Optional[EnvSpec]:
         """Random number generator of the base environment.
         """
         return self.env.spec
 
     @spec.setter
     def spec(self, spec: EnvSpec) -> None:
@@ -219,15 +229,15 @@
         """
         if action is not self.action:
             # Backup the action to perform for top-most layer of the pipeline
             self._copyto_action(action)
 
             # Make sure that the pipeline has not change since last reset
             env_derived = (
-                self.unwrapped._env_derived)  # type: ignore[attr-defined]
+                self.unwrapped.derived)  # type: ignore[attr-defined]
             if env_derived is not self:
                 raise RuntimeError(
                     "Pipeline environment has changed. Please call 'reset' "
                     "before 'step'.")
 
         # Compute the next learning step.
         # Note that forwarding 'self.env.action' enables skipping action update
@@ -436,15 +446,15 @@
         """Configure the action space.
         """
         self.action_space = self.env.action_space
 
     def _initialize_observation_space(self) -> None:
         """Configure the observation space.
         """
-        observation_space: Dict[str, gym.Space[Any]] = OrderedDict()
+        observation_space: Dict[str, gym.Space[DataNested]] = OrderedDict()
         base_observation_space = deepcopy(self.env.observation_space)
         if isinstance(base_observation_space, gym.spaces.Dict):
             observation_space.update(base_observation_space)
         else:
             observation_space['measurement'] = base_observation_space
         if self.observer.state_space is not None:
             state_spaces = observation_space.setdefault(
@@ -468,15 +478,15 @@
             Internally, it can deal with multiple observers with different
             update periods. Besides, it is safe to call this method multiple
             times successively.
 
         :param measurement: Low-level measure from the environment to process
                             to get higher-level observation.
         """
-        # Get environment observation
+        # Refresh environment observation
         self.env.refresh_observation(measurement)
 
         # Update observed features if necessary
         if is_breakpoint(self.stepper_state.t, self.observe_dt, DT_EPS):
             self.observer.refresh_observation(self.env.observation)
 
     def compute_command(self, action: ActT, command: np.ndarray) -> None:
@@ -660,15 +670,15 @@
         """Configure the observation space.
 
         It gathers the original observation from the environment plus the
         internal state to of the controller, and optionally the target computed
         by the controller if requested.
         """
         # Append the controller's target to the observation if requested
-        observation_space: Dict[str, gym.Space[Any]] = OrderedDict()
+        observation_space: Dict[str, gym.Space[DataNested]] = OrderedDict()
         base_observation_space = deepcopy(self.env.observation_space)
         if isinstance(base_observation_space, gym.spaces.Dict):
             observation_space.update(base_observation_space)
         else:
             observation_space['measurement'] = base_observation_space
         if self.controller.state_space is not None:
             state_spaces = observation_space.setdefault(
@@ -760,15 +770,15 @@
         # Initialize base class
         super().__init__(env)
 
         # Initialize some proxies for fast lookup
         self._step_dt = self.env.step_dt
 
         # Pre-allocated memory for the observation
-        self.observation: TransformedObsT = zeros(self.observation_space)
+        self.observation = zeros(self.observation_space)
 
         # Bind action of the base environment
         assert self.action_space.contains(self.env.action)
         self.action = self.env.action
 
     def _setup(self) -> None:
         """Configure the wrapper.
```

## gym_jiminy/common/blocks/proportional_derivative_controller.py

```diff
@@ -45,61 +45,64 @@
     # Make sure that dt is not negative
     assert dt >= 0.0, "Integration backward in time is not supported."
 
     # Early return if timestep is too small
     if abs(dt) < 1e-9:
         return
 
-    # Split position, velocity and acceleration orders for convenience
+    # Split position, velocity and acceleration for convenience
     position, velocity, acceleration = state
-    position_min, velocity_min, acceleration_min = state_min
-    position_max, velocity_max, acceleration_max = state_max
 
-    # Clip acceleration
-    acceleration[:] = np.minimum(
-        np.maximum(acceleration, acceleration_min), acceleration_max)
-
-    # Backup the initial velocity to later compute the clipped acceleration
-    velocity_prev = velocity.copy()
-
-    # Integrate acceleration 1-step ahead
-    velocity += acceleration * dt
-
-    # Make sure that "true" velocity bounds are satisfied
-    velocity[:] = np.minimum(np.maximum(velocity, velocity_min), velocity_max)
-
-    # Force slowing down early enough to avoid violating acceleration limits
-    # when hitting position bounds.
-    horizon = np.maximum(
-        np.floor(np.abs(velocity_prev) / acceleration_max / dt) * dt, dt)
-    position_min_delta = position_min - position
-    position_max_delta = position_max - position
-    drift = 0.5 * (horizon[horizon > dt] * (horizon[horizon > dt] - dt))
-    position_min_delta[horizon > dt] -= drift * acceleration_max[horizon > dt]
-    position_max_delta[horizon > dt] += drift * acceleration_max[horizon > dt]
-    velocity_min = position_min_delta / horizon
-    velocity_max = position_max_delta / horizon
-    velocity[:] = np.minimum(np.maximum(velocity, velocity_min), velocity_max)
-
-    # Velocity after hitting bounds must be cancellable in a single time step
-    velocity_mask = np.abs(velocity) > dt * acceleration_max
-    velocity_min = - np.maximum(
-        position_min_delta[velocity_mask] / velocity[velocity_mask], dt
-        ) * acceleration_max[velocity_mask]
-    velocity_max = np.maximum(
-        position_max_delta[velocity_mask] / velocity[velocity_mask], dt
-        ) * acceleration_max[velocity_mask]
-    velocity[velocity_mask] = np.minimum(
-        np.maximum(velocity[velocity_mask], velocity_min), velocity_max)
+    # Loop over motors individually as it is faster than masked vectorization
+    _, dim = state.shape
+    for i in range(dim):
+        # Split position, velocity and acceleration bounds
+        position_min, velocity_min, acceleration_min = state_min[:, i]
+        position_max, velocity_max, acceleration_max = state_max[:, i]
+
+        # Clip acceleration
+        acceleration[i] = min(
+            max(acceleration[i], acceleration_min), acceleration_max)
+
+        # Backup the initial velocity to later compute the clipped acceleration
+        velocity_prev = velocity[i]
+
+        # Integrate acceleration 1-step ahead
+        velocity[i] += acceleration[i] * dt
+
+        # Make sure that "true" velocity bounds are satisfied
+        velocity[i] = min(max(velocity[i], velocity_min), velocity_max)
+
+        # Force slowing down early enough to avoid violating acceleration
+        # limits when hitting position bounds.
+        horizon = max(
+            int(abs(velocity_prev) / acceleration_max / dt) * dt, dt)
+        position_min_delta = position_min - position[i]
+        position_max_delta = position_max - position[i]
+        if horizon > dt:
+            drift = 0.5 * (horizon * (horizon - dt)) * acceleration_max
+            position_min_delta -= drift
+            position_max_delta += drift
+        velocity_min = position_min_delta / horizon
+        velocity_max = position_max_delta / horizon
+        velocity[i] = min(max(velocity[i], velocity_min), velocity_max)
+
+        # Velocity after hitting bounds must be cancellable in a single step
+        if np.abs(velocity[i]) > dt * acceleration_max:
+            velocity_min = - max(
+                position_min_delta / velocity[i], dt) * acceleration_max
+            velocity_max = max(
+                position_max_delta / velocity[i], dt) * acceleration_max
+            velocity[i] = min(max(velocity[i], velocity_min), velocity_max)
 
-    # Back-propagate velocity clipping at the acceleration-level
-    acceleration[:] = (velocity - velocity_prev) / dt
+        # Back-propagate velocity clipping at the acceleration-level
+        acceleration[i] = (velocity[i] - velocity_prev) / dt
 
-    # Integrate position 1-step ahead
-    position += dt * velocity
+        # Integrate position 1-step ahead
+        position[i] += dt * velocity[i]
 
 
 @nb.jit(nopython=True, cache=True, fastmath=True)
 def pd_controller(q_measured: np.ndarray,
                   v_measured: np.ndarray,
                   command_state: np.ndarray,
                   command_state_lower: np.ndarray,
@@ -518,15 +521,15 @@
                  env: InterfaceJiminyEnv[BaseObsT, np.ndarray],
                  *,
                  update_ratio: int = -1,
                  order: int = 1) -> None:
         """
         :param update_ratio: Ratio between the update period of the controller
                              and the one of the subsequent controller. -1 to
-                             match the simulation timestep of the environment.
+                             match the environment step `env.step_dt`.
                              Optional: -1 by default.
         :param order: Derivative order of the action. It accepts position or
                       velocity (respectively 0 or 1).
                       Optional: 1 by default.
         """
         # Make sure that the specified derivative order is valid
         assert order in (0, 1), "Derivative order out-of-bounds"
```

## gym_jiminy/common/envs/generic.py

```diff
@@ -5,20 +5,20 @@
 import os
 import math
 import weakref
 import logging
 import tempfile
 from copy import deepcopy
 from collections import OrderedDict
-from collections.abc import Mapping
+from collections.abc import Mapping, Sequence
 from functools import partial
 from typing import (
     Dict, Any, List, cast, no_type_check, Optional, Tuple, Callable, Union,
-    SupportsFloat, Iterator,  Generic, Sequence, Mapping as MappingT,
-    MutableMapping as MutableMappingT)
+    SupportsFloat, Iterator,  Generic, Sequence as SequenceT,
+    Mapping as MappingT, MutableMapping as MutableMappingT)
 
 import numpy as np
 from gymnasium import spaces
 from gymnasium.core import RenderFrame
 
 import jiminy_py.core as jiminy
 from jiminy_py import tree
@@ -81,15 +81,15 @@
 
 
 LOGGER = logging.getLogger(__name__)
 
 
 class _LazyDictItemFilter(Mapping):
     def __init__(self,
-                 dict_packed: MappingT[str, Sequence[Any]],
+                 dict_packed: MappingT[str, SequenceT[Any]],
                  item_index: int) -> None:
         self.dict_packed = dict_packed
         self.item_index = item_index
 
     def __getitem__(self, name: str) -> Any:
         return self.dict_packed[name][self.item_index]
 
@@ -138,44 +138,58 @@
         :param enforce_bounded_spaces:
             Whether to enforce finite bounds for the observation and action
             spaces. If so, then '\*_MAX' are used whenever it is necessary.
             Note that whose bounds are very spread to make sure it is suitable
             for the vast majority of systems.
         :param debug: Whether the debug mode must be enabled. Doing it enables
                       telemetry recording.
-        :param viewer_kwargs: Keyword arguments used to override the original
-                              default values whenever a viewer is instantiated.
-                              This is the only way to pass custom arguments to
-                              the viewer when calling `render` method, unlike
-                              `replay` which forwards extra keyword arguments.
-                              Optional: None by default.
+        :param render_mode: Desired rendering mode, ie "human" or "rgb_array".
+                            If "human" is specified, calling `render` will open
+                            a graphical window for visualization, otherwise a
+                            rgb image is returned, as a 3D numpy array whose
+                            first dimension are the 3 red, green, blue channels
+                            and the two subsequent dimensions are the pixel
+                            height and weight respectively. `None` to select
+                            automatically the most appropriate mode based on
+                            the user-specified rendering backend if any, or the
+                            machine environment. Note that "rgb_array" does not
+                            require a graphical window manager.
+                            Optional: None by default.
         :param kwargs: Extra keyword arguments that may be useful for derived
                        environments with multiple inheritance, and to allow
                        automatic pipeline wrapper generation.
         """
         # Make sure that the simulator is single-robot
-        if tuple(robot.name for robot in simulator.robots) != ("",):
-            raise ValueError(
-                "`BaseJiminyEnv` only supports single-robot simulators.")
+        if len(simulator.robots) > 1:
+            raise NotImplementedError(
+                "Multi-robot simulation is not supported for now.")
 
         # Handling of default rendering mode
-        viewer_backend = (simulator.viewer or Viewer).backend
+        viewer_backend = (
+            (simulator.viewer or Viewer).backend or
+            simulator.viewer_kwargs.get('backend'))
         if render_mode is None:
             # 'rgb_array' by default if the backend is or will be
             # 'panda3d-sync', otherwise 'human' if available.
-            backend = (kwargs.get('backend') or viewer_backend or
-                       simulator.viewer_kwargs.get('backend') or
-                       get_default_backend())
+            backend = viewer_backend or get_default_backend()
             if backend == "panda3d-sync":
                 render_mode = 'rgb_array'
             elif 'human' in self.metadata['render_modes']:
                 render_mode = 'human'
             else:
                 render_mode = 'rgb_array'
 
+        # Force backend if none is specified and rendering mode is RGB array
+        if ("backend" not in simulator.viewer_kwargs and
+                render_mode == 'rgb_array'):
+            simulator.viewer_kwargs['backend'] = "panda3d-sync"
+
+        # Make sure that the robot name is unique
+        simulator.viewer_kwargs['robot_name'] = None
+
         # Make sure that rendering mode is valid
         assert render_mode in self.metadata['render_modes']
 
         # Backup some user arguments
         self.simulator: Simulator = simulator
         self._step_dt = step_dt
         self.render_mode = render_mode
@@ -192,15 +206,15 @@
         self._robot_state_q = np.array([])
         self._robot_state_v = np.array([])
         self._robot_state_a = np.array([])
         self.sensor_measurements: SensorMeasurementStackMap = OrderedDict(
             self.robot.sensor_measurements)
 
         # Top-most block of the pipeline to which the environment is part of
-        self._env_derived: InterfaceJiminyEnv = self
+        self.derived: InterfaceJiminyEnv = self
 
         # Store references to the variables to register to the telemetry
         self._registered_variables: MutableMappingT[
             str, Tuple[FieldNested, DataNested]] = {}
         self.log_fieldnames: MappingT[str, FieldNested] = _LazyDictItemFilter(
             self._registered_variables, 0)
 
@@ -318,15 +332,16 @@
         """Get time space.
         """
         return spaces.Box(low=0.0,
                           high=self.simulation_duration_max,
                           shape=(),
                           dtype=np.float64)
 
-    def _get_agent_state_space(self) -> spaces.Dict:
+    def _get_agent_state_space(
+            self, use_theoretical_model: bool = False) -> spaces.Dict:
         """Get state space.
 
         This method is not meant to be overloaded in general since the
         definition of the state space is mostly consensual. One must rather
         overload `_initialize_observation_space` to customize the observation
         space as a whole.
         """
@@ -350,14 +365,22 @@
                     self.robot.pinocchio_model.joints[joint_index].idx_v)
                 velocity_limit[
                     joint_velocity_index + np.arange(3)] = FLEX_VEL_ANG_MAX
 
             if not model_options['joints']['enableVelocityLimit']:
                 velocity_limit[joint_velocity_indices] = JOINT_VEL_MAX
 
+        # Deduce bounds associated the theoretical model from the extended one
+        if use_theoretical_model:
+            position_limit_lower, position_limit_upper = map(
+                self.robot.get_theoretical_position_from_extended,
+                (position_limit_lower, position_limit_upper))
+            velocity_limit = self.robot.get_theoretical_velocity_from_extended(
+                velocity_limit)
+
         # Aggregate position and velocity bounds to define state space
         return spaces.Dict(OrderedDict(
             q=spaces.Box(low=position_limit_lower,
                          high=position_limit_upper,
                          dtype=np.float64),
             v=spaces.Box(low=-velocity_limit,
                          high=velocity_limit,
@@ -764,15 +787,15 @@
             options or {}).get("reset_hook")
         env: InterfaceJiminyEnv = self
         if reset_hook is not None:
             assert callable(reset_hook)
             env_derived = reset_hook() or env
             assert env_derived.unwrapped is self
             env = env_derived
-        self._env_derived = env
+        self.derived = env
 
         # Instantiate the actual controller.
         # Note that a weak reference must be used to avoid circular reference.
         self.robot.controller = jiminy.FunctionalController(
             partial(type(env)._controller_handle, weakref.proxy(env)))
 
         # Configure the maximum number of steps
@@ -912,15 +935,15 @@
 
         # Update shared buffers
         self._refresh_buffers()
 
         # Update the observer at the end of the step.
         # This is necessary because, internally, it is called at the beginning
         # of the every integration steps, during the controller update.
-        self._env_derived._observer_handle(
+        self.derived._observer_handle(
             self.stepper_state.t,
             self._robot_state_q,
             self._robot_state_v,
             self.robot.sensor_measurements)
 
         # Make sure there is no 'nan' value in observation
         if is_nan(self._robot_state_a):
@@ -1013,14 +1036,15 @@
 
         :param enable_block_states: Whether to display the internal state of
                                     all blocks.
         :param kwargs: Extra keyword arguments to forward to `simulator.plot`.
         """
         # Call base implementation
         figure = self.simulator.plot(**kwargs)
+        assert not isinstance(figure, Sequence)
 
         # Extract log data
         log_vars = self.simulator.log_data.get("variables", {})
         if not log_vars:
             raise RuntimeError(
                 "Nothing to plot. Please run a simulation before calling "
                 "`plot` method.")
@@ -1255,15 +1279,15 @@
         # Initialize the simulation
         obs, info = self.reset()
         reward, terminated, truncated = None, False, False
 
         # Run the simulation
         info_episode = [info]
         try:
-            env = self._env_derived
+            env = self.derived
             while not (terminated or truncated or (
                     horizon is not None and self.num_steps > horizon)):
                 action = policy_fn(obs, reward, terminated or truncated, info)
                 obs, reward, terminated, truncated, info = env.step(action)
                 info_episode.append(info)
             self.simulator.stop()
         except KeyboardInterrupt:
@@ -1441,15 +1465,18 @@
 
     def _refresh_buffers(self) -> None:
         """Refresh internal buffers that must be updated manually.
 
         .. note::
             This method is called after every internal `engine.step` and before
             refreshing the observation one last time. As such, it is the right
-            place to update shared data between `is_done` and `compute_reward`.
+            place to update shared data between `has_terminated` and
+            `compute_reward`. However, it is not appropriate for quantities
+            involved in `refresh_observation` not `compute_command`, which may
+            be called more often than once per step.
 
         .. note::
             `_initialize_buffers` method can be used to initialize buffers that
             may requires special care.
 
         .. warning::
             Be careful when using this method to update buffers involved in
```

## gym_jiminy/common/quantities/generic.py

```diff
@@ -138,14 +138,18 @@
 
     The orientation of all frames is exposed to the user as a dictionary whose
     keys are the individual frame names. Internally, data are stored in batched
     2D contiguous array for efficiency. The first dimension are the 3 Euler
     angles (roll, pitch, yaw) components, while the second one are individual
     frames with the same ordering as 'self.frame_names'.
 
+    The expected maximum speedup wrt computing Euler angles individually is
+    about x15, which is achieved asymptotically for more than 100 frames. It is
+    already x5 faster for 5 frames, x7 for 10 frames, and x9 for 20 frames.
+
     .. note::
         This quantity does not allow for specifying frames directly. There is
         no way to get the orientation of multiple frames at once for now.
     """
     def __init__(self,
                  env: InterfaceJiminyEnv,
                  parent: Optional[AbstractQuantity]) -> None:
@@ -263,14 +267,16 @@
 
         # Call base implementation.
         # The quantity is now considered active at this point.
         super().initialize()
 
         # Force re-initializing shared data if the active set has changed
         if not was_active:
-            self.requirements["data"].reset()
+            # Must reset the tracking for shared computation systematically,
+            # just in case the optimal computation path has changed.
+            self.requirements["data"].reset(reset_tracking=True)
 
     def refresh(self) -> np.ndarray:
         # Return a slice of batched data.
         # Note that mapping from frame name to frame index in batched data
         # cannot be pre-computed as it may changed dynamically.
         return self.data[self.frame_name]
```

## gym_jiminy/common/utils/__init__.py

```diff
@@ -13,15 +13,16 @@
                    quat_average,
                    rpy_to_matrix,
                    rpy_to_quat,
                    transforms_to_vector,
                    compute_tilt_from_quat,
                    swing_from_vector,
                    remove_twist_from_quat)
-from .spaces import (DataNested,
+from .spaces import (StructNested,
+                     DataNested,
                      FieldNested,
                      ArrayOrScalar,
                      get_bounds,
                      zeros,
                      fill,
                      copyto,
                      copy,
@@ -56,14 +57,15 @@
     'quat_average',
     'rpy_to_matrix',
     'rpy_to_quat',
     'transforms_to_vector',
     'compute_tilt_from_quat',
     'swing_from_vector',
     'remove_twist_from_quat',
+    'StructNested',
     'DataNested',
     'FieldNested',
     'ArrayOrScalar',
     'get_bounds',
     'sample',
     'zeros',
     'fill',
```

## gym_jiminy/common/utils/misc.py

```diff
@@ -30,15 +30,14 @@
     custom statistical distribution to `sample` method.
     """
     def __call__(self, rg: np.random.Generator, *args: Any, **kwargs: Any
                  ) -> ArrayOrScalar:
         ...
 
 
-@nb.jit(nopython=True, cache=True, inline='always')
 def is_breakpoint(t: float, dt: float, eps: float) -> bool:
     """Check if 't' is multiple of 'dt' at a given precision 'eps'.
 
     :param t: Current time.
     :param dt: Timestep.
     :param eps: Precision.
```

## gym_jiminy/common/utils/spaces.py

```diff
@@ -162,14 +162,18 @@
         value = np.zeros_like(space.nvec, dtype=dtype or np.int64)
     elif isinstance(space, gym.spaces.MultiBinary):
         value = np.zeros(space.n, dtype=dtype or np.int8)
     if value is not None:
         if enforce_bounds:
             value = clip(value, space)
         return value
+    if not isinstance(space, gym.Space):
+        raise ValueError(
+            "All spaces must derived from `gym.Space`, including tuple and "
+            "dict containers.")
     raise NotImplementedError(
         f"Space of type {type(space)} is not supported.")
 
 
 def fill(data: DataNested, fill_value: Union[float, int, np.number]) -> None:
     """Set every element of 'data' from `gym.Space` to scalar 'fill_value'.
 
@@ -211,36 +215,39 @@
     are still references.
 
     :param data: Hierarchical data structure to copy without allocation.
     """
     return cast(DataNestedT, tree.unflatten_as(data, tree.flatten(data)))
 
 
+@no_type_check
 def clip(data: DataNested, space: gym.Space[DataNested]) -> DataNested:
     """Clip data from `gym.Space` to make sure it is within bounds.
 
     .. note:
         None of the leaves of the returned data structured is sharing memory
         with the original one, even if clipping had no effect. This alleviate
         the need of calling 'deepcopy' afterward.
 
     :param data: Data to clip.
     :param space: `gym.Space` on which to operate.
     """
-    # FIXME: Add support of `gym.spaces.Tuple`
-    if not isinstance(space, gym.spaces.Dict):
-        return _array_clip(data, *get_bounds(space))
-    assert isinstance(data, dict)
-
-    out: Dict[str, DataNested] = OrderedDict()
-    for field, subspace in space.spaces.items():
-        out[field] = clip(data[field], subspace)
-    return out
+    data_type = type(data)
+    if tree.issubclass_mapping(data_type):
+        return data_type({
+            field: clip(data[field], subspace)
+            for field, subspace in space.spaces.items()})
+    if tree.issubclass_sequence(data_type):
+        return data_type(tuple(
+            clip(data[i], subspace)
+            for i, subspace in enumerate(space.spaces)))
+    return _array_clip(data, *get_bounds(space))
 
 
+@no_type_check
 def contains(data: DataNested,
              space: gym.Space[DataNested],
              tol_abs: float = 0.0,
              tol_rel: float = 0.0) -> bool:
     """Check if all leaves of a nested data structure are within bounds of
     their respective `gym.Space`, up to some tolerance threshold. If both
     absolute and relative tolerances are provided, then satisfying only one of
@@ -250,27 +257,29 @@
     `gym.spaces.Discrete` and `gym.spaces.MultiDiscrete`.
 
     :param data: Data structure to check.
     :param space: `gym.Space` on which to operate.
     :param tol_abs: Absolute tolerance.
     :param tol_rel: Relative tolerance.
     """
-    if not isinstance(space, gym.spaces.Dict):
-        return _array_contains(data, *get_bounds(space), tol_abs, tol_rel)
-    assert isinstance(data, dict)
-
-    return all(contains(data[field], subspace, tol_abs, tol_rel)
-               for field, subspace in space.spaces.items())
+    data_type = type(data)
+    if tree.issubclass_mapping(data_type):
+        return all(contains(data[field], subspace, tol_abs, tol_rel)
+                   for field, subspace in space.spaces.items())
+    if tree.issubclass_sequence(data_type):
+        return all(contains(data[i], subspace, tol_abs, tol_rel)
+                   for i, subspace in enumerate(space.spaces))
+    return _array_contains(data, *get_bounds(space), tol_abs, tol_rel)
 
 
 @no_type_check
 def build_reduce(fn: Callable[..., ValueInT],
                  op: Optional[Callable[[ValueOutT, ValueInT], ValueOutT]],
                  dataset: SequenceT[DataNested],
-                 space: Optional[gym.spaces.Dict],
+                 space: Optional[gym.Space[DataNested]],
                  arity: Optional[Literal[0, 1]],
                  *args: Any,
                  initializer: Optional[Callable[[], ValueOutT]] = None,
                  forward_bounds: bool = True) -> Callable[..., ValueOutT]:
     """Generate specialized callable applying transform and reduction on all
     leaves of given nested space.
 
@@ -308,16 +317,17 @@
                reduction.
     :param op: Optional reduction operator applied cumulatively on all leaves
                after transform. See 'functools.reduce' documentation for
                details. `None` to only apply transform on all leaves without
                reduction. This is useful when apply in-place transform.
     :param data: Pre-allocated nested data structure. Optional if the space is
                  provided but hardly relevant.
-    :param space: `gym.spaces.Dict` on which to operate. Optional iif the
-                  nested data structure is provided.
+    :param space: Container space on which to operate (eg `gym.spaces.Dict` or
+                  `gym.spaces.Tuple`). Optional iif the nested data structure
+                  is provided.
     :param arity: Arity of the generated callable. `None` to indicate that it
                   must be determined at runtime, which is slower.
     :param args: Extra arguments to systematically forward as transform input
                  for all leaves. Note that, as for Python built-ins methods,
                  keywords are not supported for the sake of efficiency.
     :param initializer: Function used to compute the initial value before
                         starting reduction. Optional if the reduction operator
```

## gym_jiminy/common/wrappers/__init__.py

```diff
@@ -1,17 +1,16 @@
 # pylint: disable=missing-module-docstring
 
 from .observation_filter import FilterObservation
-from .observation_stack import PartialObservationStack, StackedJiminyEnv
+from .observation_stack import StackedJiminyEnv
 from .normalize import NormalizeAction, NormalizeObservation
 from .flatten import FlattenAction, FlattenObservation
 
 
 __all__ = [
     'FilterObservation',
-    'PartialObservationStack',
     'StackedJiminyEnv',
     'NormalizeAction',
     'NormalizeObservation',
     'FlattenAction',
     'FlattenObservation',
 ]
```

## gym_jiminy/common/wrappers/flatten.py

```diff
@@ -16,16 +16,16 @@
                      ActT,
                      InterfaceJiminyEnv,
                      BaseTransformObservation,
                      BaseTransformAction)
 from ..utils import get_bounds, build_flatten
 
 
-FlattenedObsT: TypeAlias = ObsT
-FlattenedActT: TypeAlias = ActT
+FlattenedObsT: TypeAlias = npt.NDArray[np.float64]
+FlattenedActT: TypeAlias = npt.NDArray[np.float64]
 
 
 class FlattenObservation(BaseTransformObservation[FlattenedObsT, ObsT, ActT],
                          Generic[ObsT, ActT]):
     """Flatten the observation space of a pipeline environment. It will appear
     as a simple one-dimension vector.
```

## gym_jiminy/common/wrappers/observation_filter.py

```diff
@@ -1,88 +1,193 @@
 """This module implements a block transformation for filtering out some of the
 keys of the observation space of an environment that may be arbitrarily nested.
 """
+from operator import getitem
+from functools import reduce
 from collections import OrderedDict
-from typing import Sequence, Union, Generic
+from typing import (
+    Sequence, Set, Tuple, Union, Generic, TypeVar, Type, no_type_check)
 from typing_extensions import TypeAlias
 
 import gymnasium as gym
+from jiminy_py.tree import (
+    flatten_with_path, issubclass_mapping, issubclass_sequence)
 
-from ..bases import (ObsT,
+from ..bases import (NestedObsT,
                      ActT,
                      InterfaceJiminyEnv,
                      BaseTransformObservation)
+from ..utils import DataNested, copy
 
 
-FilteredObsType: TypeAlias = ObsT
+SpaceOrDataT = TypeVar(
+    'SpaceOrDataT', bound=Union[DataNested, gym.Space[DataNested]])
+FilteredObsT: TypeAlias = NestedObsT
 
 
-class FilterObservation(BaseTransformObservation[FilteredObsType, ObsT, ActT],
-                        Generic[ObsT, ActT]):
+@no_type_check
+def _copy_filtered(data: SpaceOrDataT,
+                   path_filtered_leaves: Set[Tuple[str, ...]]) -> SpaceOrDataT:
+    """Partially shallow copy some nested data structure, so that all leaves
+    being filtered in are still references but their corresponding containers
+    are copies.
+
+    :param data: Hierarchical data structure to copy without allocation.
+    :param path_filtered_leaves: Set gathering the paths of all leaves that
+                                 must be kept. Each path is a tuple of keys
+                                 to access a given leaf recursively.
+    """
+    # Special handling if no leaf to filter has been specified
+    if not path_filtered_leaves:
+        data_type = type(data)
+        if issubclass_mapping(data_type) or issubclass_sequence(data_type):
+            return data_type()
+        return data
+
+    # Shallow copy the whole data structure
+    out = copy(data)
+
+    # Convert all parent containers to mutable dictionary
+    type_filtered_nodes: Sequence[Type] = []
+    out_flat = flatten_with_path(out)
+    for key_nested, _ in out_flat:
+        if key_nested not in path_filtered_leaves:
+            continue
+        for i in range(1, len(key_nested) + 1):
+            # Extract parent container
+            *key_nested_parent, key_leaf = key_nested[:i]
+            if key_nested_parent:
+                *key_nested_container, key_parent = key_nested_parent
+                container = reduce(getitem, key_nested_container, out)
+                parent = container[key_parent]
+            else:
+                parent = out
+
+            # Convert parent container to mutable dictionary
+            parent_type = type(parent)
+            type_filtered_nodes.append(parent_type)
+            if parent_type in (list, dict, OrderedDict):
+                continue
+            if issubclass(parent_type, gym.Space):
+                parent = parent.spaces
+            if issubclass_mapping(parent_type):
+                parent = dict(parent.items())
+            elif issubclass_sequence(parent_type):
+                parent = dict(enumerate(parent))
+            else:
+                raise NotImplementedError(
+                    f"Unsupported container type: '{parent_type}'")
+
+            # Re-assign parent data structure
+            if key_nested_parent:
+                container[key_parent] = parent
+            else:
+                out = parent
+
+    # Remove unnecessary keys
+    for key_nested, _ in out_flat:
+        if key_nested in path_filtered_leaves:
+            continue
+        for i in range(len(key_nested))[::-1]:
+            if any(key_nested[:i] == path[:i]
+                   for path in path_filtered_leaves):
+                break
+        *key_nested_parent, key_leaf = key_nested[:(i + 1)]
+        try:
+            parent = reduce(getitem, key_nested_parent, out)
+            del parent[key_leaf]
+        except KeyError:
+            # Some nested keys may have been deleted previously
+            pass
+
+    # Restore original parent container types
+    parent_type_it = iter(type_filtered_nodes[::-1])
+    for key_nested, _ in out_flat[::-1]:
+        if key_nested not in path_filtered_leaves:
+            continue
+        for i in range(1, len(key_nested) + 1)[::-1]:
+            # Extract parent container
+            *key_nested_parent, _ = key_nested[:i]
+            if key_nested_parent:
+                *key_nested_container, key_parent = key_nested_parent
+                container = reduce(getitem, key_nested_container, out)
+                parent = container[key_parent]
+            else:
+                parent = out
+
+            # Restore original container type if not already done
+            parent_type = next(parent_type_it)
+            if isinstance(parent, parent_type):
+                continue
+            if issubclass_mapping(parent_type):
+                parent = parent_type(tuple(parent.items()))
+            elif issubclass_sequence(parent_type):
+                parent = parent_type(tuple(parent.values()))
+
+            # Re-assign output data structure
+            if key_nested_parent:
+                container[key_parent] = parent
+            else:
+                out = parent
+    return out
+
+
+class FilterObservation(
+        BaseTransformObservation[FilteredObsT, NestedObsT, ActT],
+        Generic[NestedObsT, ActT]):
     """Filter nested observation space.
 
-    This wrapper does not nothing but providing an observation only exposing
-    a subset of all the branches and leaves of the original observation space.
-    For flattening the observation space after filtering, you should wrap the
-    environment with `FlattenObservation` as yet another layer.
+    This wrapper does nothing but providing an observation only exposing a
+    subset of all the leaves of the original observation space. For flattening
+    the observation space after filtering, you should wrap the environment with
+    `FlattenObservation` as yet another layer.
     """
     def __init__(self,
-                 env: InterfaceJiminyEnv[ObsT, ActT],
-                 nested_filter_keys: Sequence[Union[Sequence[str], str]]
+                 env: InterfaceJiminyEnv[NestedObsT, ActT],
+                 nested_filter_keys: Sequence[
+                    Union[Sequence[Union[str, int]], Union[str, int]]]
                  ) -> None:
         # Make sure that the observation space derives from 'gym.spaces.Dict'
         assert isinstance(env.observation_space, gym.spaces.Dict)
 
         # Make sure all nested keys are stored in sequence
-        self.nested_filter_keys = []
+        assert not isinstance(nested_filter_keys, str)
+        self.nested_filter_keys: Sequence[Sequence[Union[str, int]]] = []
         for key_nested in nested_filter_keys:
-            if isinstance(key_nested, str):
+            if isinstance(key_nested, (str, int)):
                 key_nested = (key_nested,)
-            self.nested_filter_keys.append(key_nested)
+            self.nested_filter_keys.append(tuple(key_nested))
 
-        # Remove redundant nested keys if any
-        for i, key_nested in list(enumerate(self.nested_filter_keys))[::-1]:
-            for j, path in list(enumerate(self.nested_filter_keys[:i]))[::-1]:
-                if path[:len(key_nested)] == key_nested:
-                    self.nested_filter_keys.pop(j)
-                elif path == key_nested[:len(path)]:
-                    self.nested_filter_keys.pop(i)
-                    break
+        # Get all paths associated with leaf values that must be stacked
+        self.path_filtered_leaves: Set[Tuple[Union[str, int], ...]] = set()
+        for path, _ in flatten_with_path(env.observation_space):
+            if any(path[:len(e)] == e for e in self.nested_filter_keys):
+                self.path_filtered_leaves.add(path)
+
+        # Make sure that some keys are preserved
+        if not self.path_filtered_leaves:
+            raise ValueError(
+                "At least one observation leaf must be preserved.")
 
         # Initialize base class
         super().__init__(env)
 
-        # Bind observation of the environment for all filtered keys
-        self.observation = OrderedDict()
-        for key_nested in self.nested_filter_keys:
-            observation_filtered = self.observation
-            observation = self.env.observation
-            for key in key_nested[:-1]:
-                assert isinstance(observation, dict)
-                observation = observation[key]
-                observation_filtered = observation_filtered.setdefault(
-                    key, OrderedDict())
-            assert isinstance(observation, dict)
-            observation_filtered[key_nested[-1]] = observation[key_nested[-1]]
+        # Bind observation of the environment for all filtered keys.
+        # Note that all parent containers of the filtered leaves must be
+        # constructible from standard `dict` or `tuple` objects, which is the
+        # case for all standard `gym.Space`.
+        self.observation = _copy_filtered(
+            self.env.observation, self.path_filtered_leaves)
 
     def _initialize_observation_space(self) -> None:
         """Configure the observation space.
 
-        It gathers a subset of all the branches and leaves of the original
-        observation space without any further processing.
+        It gathers a subset of all the leaves of the original observation space
+        without any further processing.
         """
-        self.observation_space = gym.spaces.Dict()
-        for key_nested in self.nested_filter_keys:
-            space_filtered = self.observation_space
-            space = self.env.observation_space
-            for key in key_nested[:-1]:
-                assert isinstance(space, gym.spaces.Dict)
-                space = space[key]
-                space_filtered = space_filtered.spaces.setdefault(
-                    key, gym.spaces.Dict())  # type: ignore[assignment]
-            assert isinstance(space, gym.spaces.Dict)
-            space_filtered[key_nested[-1]] = space[key_nested[-1]]
+        self.observation_space = _copy_filtered(
+            self.env.observation_space, self.path_filtered_leaves)
 
     def transform_observation(self) -> None:
         """No-op transform since the transform observation is sharing memory
         with the wrapped one since it is just a partial view.
         """
```

## gym_jiminy/common/wrappers/observation_stack.py

```diff
@@ -1,261 +1,254 @@
 """ TODO: Write documentation.
 """
-from copy import deepcopy
-from operator import getitem
-from functools import reduce
+import logging
 from collections import deque
-from typing import (
-    List, Any, Dict, Optional, Tuple, Sequence, Iterator, Union, Generic,
-    SupportsFloat)
+from typing import List, Optional, Tuple, Set, Sequence, Union, Generic
 from typing_extensions import TypeAlias
 
 import numpy as np
-
 import gymnasium as gym
+from jiminy_py.core import (  # pylint: disable=no-name-in-module
+    array_copyto, multi_array_copyto)
+from jiminy_py.tree import flatten_with_path, unflatten_as
 
-from ..utils import is_breakpoint, zeros, copy, copyto
 from ..bases import (DT_EPS,
-                     ObsT,
+                     NestedObsT,
                      ActT,
-                     InfoType,
                      EngineObsType,
                      InterfaceJiminyEnv,
                      BasePipelineWrapper)
+from ..utils import is_breakpoint, zeros, copy
+
 
+StackedObsT: TypeAlias = NestedObsT
 
-StackedObsType: TypeAlias = ObsT
+LOGGER = logging.getLogger(__name__)
 
 
-class PartialObservationStack(
-        gym.Wrapper,  # [StackedObsType, ActT, ObsT, ActT],
-        Generic[ObsT, ActT]):
-    """Observation wrapper that partially stacks observations in a rolling
-    manner.
+class StackedJiminyEnv(
+        BasePipelineWrapper[StackedObsT, ActT, NestedObsT, ActT],
+        Generic[NestedObsT, ActT]):
+    """Partially stack observations in a rolling manner.
 
     This wrapper combines and extends OpenAI Gym wrappers `FrameStack` and
     `FilteredJiminyEnv` to support nested filter keys.
 
     It adds one extra dimension to all the leaves of the original observation
-    spaces that must be stacked. If so, the first dimension corresponds to the
-    individual timesteps (from oldest [0] to latest [-1]).
+    spaces that must be stacked. In such a case, the first dimension
+    corresponds to the individual timesteps (from oldest `0` to latest `-1`).
 
     .. note::
-        The observation space must be `gym.spaces.Dict`, while, ultimately,
-        stacked leaf fields must be `gym.spaces.Box`.
+        The standard container spaces `gym.spaces.Dict` and `gym.spaces.Tuple`
+        are both supported. All the stacked leaf spaces must have type
+        `gym.spaces.Box`.
+
+    .. note::
+        The latest frame of the stacked leaf observations corresponds to their
+        latest respective values no matter what. It will frozen when shifted to
+        the left.
     """
     def __init__(self,
-                 env: gym.Env[ObsT, ActT],
+                 env: InterfaceJiminyEnv[NestedObsT, ActT],
+                 *,
                  num_stack: int,
-                 nested_filter_keys: Optional[
-                     Sequence[Union[Sequence[str], str]]] = None,
-                 **kwargs: Any):
+                 nested_filter_keys: Optional[Sequence[
+                    Union[Sequence[Union[str, int]], Union[str, int]]]] = None,
+                 skip_frames_ratio: int = -1) -> None:
         """
         :param env: Environment to wrap.
-        :param nested_filter_keys: List of nested observation fields to stack.
-                                   Those fields does not have to be leaves. If
-                                   not, then every leaves fields from this root
-                                   will be stacked.
-        :param num_stack: Number of observation frames to partially stack.
-        :param kwargs: Extra keyword arguments to allow automatic pipeline
-                       wrapper generation.
-        """
-        # pylint: disable=unused-argument
-
-        # Sanitize user arguments if necessary
-        assert isinstance(env.observation_space, gym.spaces.Dict)
+        :param num_stack: Number of observation frames to keep stacked.
+        :param nested_filter_keys: List of nested observation paths to stack.
+                                   If a nested path is not associated with a
+                                   leaf, then every leaves starting from this
+                                   root path will be stacked.
+                                   Optional: All leaves will be stacked by
+                                   default.
+        :param skip_frames_ratio: Number of observation refresh to skip between
+                                  each update of the stacked leaf values. -1 to
+                                  update only once per environment step.
+                                  Optional: -1 by default.
+        """
+        # Handling of default argument(s)
+        env_observation_space: gym.Space = env.observation_space
+        assert isinstance(env_observation_space, gym.spaces.Dict)
         if nested_filter_keys is None:
-            nested_filter_keys = list(
-                env.observation_space.keys())  # type: ignore[attr-defined]
-
-        # Backup user argument(s)
-        self.nested_filter_keys: List[List[str]] = list(
-            list(fields) for fields in nested_filter_keys)
-        self.num_stack = num_stack
-
-        # Initialize base wrapper.
-        # Note that `gym.Wrapper` automatically binds the action/observation to
-        # the one of the environment if not overridden explicitly.
-        super().__init__(env)  # Do not forward extra arguments, if any
-
-        # Get the leaf fields to stack
-        def _get_branches(root: Any) -> Iterator[List[str]]:
-            if isinstance(root, gym.spaces.Dict):
-                for field, node in root.spaces.items():
-                    if isinstance(node, gym.spaces.Dict):
-                        for path in _get_branches(node):
-                            yield [field] + path
-                    else:
-                        yield [field]
-
-        self.leaf_fields_list: List[List[str]] = []
-        for fields in self.nested_filter_keys:
-            root_field = reduce(getitem,  # type: ignore[arg-type]
-                                fields, self.env.observation_space)
-            if isinstance(root_field, gym.spaces.Dict):
-                leaf_paths = _get_branches(root_field)
-                self.leaf_fields_list += [fields + path for path in leaf_paths]
-            else:
-                self.leaf_fields_list.append(fields)
-
-        # Compute stacked observation space
-        self.observation_space = deepcopy(self.env.observation_space)
-        for fields in self.leaf_fields_list:
-            assert isinstance(self.observation_space, gym.spaces.Dict)
-            root_space = reduce(getitem,  # type: ignore[arg-type]
-                                fields[:-1],  self.observation_space)
-            space = root_space[fields[-1]]
-            if not isinstance(space, gym.spaces.Box):
-                raise TypeError(
-                    "Stacked leaf fields must be associated with "
-                    "`gym.spaces.Box` space")
-            low = np.repeat(space.low[np.newaxis], self.num_stack, axis=0)
-            high = np.repeat(space.high[np.newaxis], self.num_stack, axis=0)
-            assert space.dtype is not None
-            assert issubclass(space.dtype.type, (np.floating, np.integer))
-            root_space[fields[-1]] = gym.spaces.Box(
-                low=low, high=high, dtype=space.dtype.type)
-
-        # Bind observation of the environment for all keys but the stacked ones
-        if isinstance(self.env, InterfaceJiminyEnv):
-            self.observation = copy(self.env.observation)
-            for fields in self.leaf_fields_list:
-                assert isinstance(self.observation_space, gym.spaces.Dict)
-                root_obs = reduce(getitem, fields[:-1], self.observation)
-                space = reduce(getitem,  # type: ignore[arg-type]
-                               fields, self.observation_space)
-                root_obs[fields[-1]] = zeros(space)
-        else:
-            # Fallback to classical memory allocation
-            self.observation = zeros(self.observation_space)
-
-        # Allocate internal frames buffers
-        self._frames: List[deque] = [
-            deque(maxlen=self.num_stack) for _ in self.leaf_fields_list]
-
-    def _setup(self) -> None:
-        """ TODO: Write documentation.
-        """
-        # Reset frames to zero
-        for fields, frames in zip(self.leaf_fields_list, self._frames):
-            assert isinstance(self.env.observation_space, gym.spaces.Dict)
-            leaf_space = reduce(getitem,  # type: ignore[arg-type]
-                                fields, self.env.observation_space)
-            for _ in range(self.num_stack):
-                frames.append(zeros(leaf_space))
-
-    def refresh_observation(self, measurement: ObsT) -> None:
-        """ TODO: Write documentation.
-        """
-        # Copy measurement if impossible to bind memory in the first place
-        if not isinstance(self.env, InterfaceJiminyEnv):
-            copyto(self.observation, measurement)
-
-        # Backup the nested observation fields to stack.
-        # Leaf values are copied to ensure they do not get altered later on.
-        for fields, frames in zip(self.leaf_fields_list, self._frames):
-            leaf_obs = reduce(getitem,  # type: ignore[arg-type]
-                              fields, measurement)
-            assert isinstance(leaf_obs, np.ndarray)
-            frames.append(leaf_obs.copy())
-
-        # Update nested fields of the observation by the stacked ones
-        for fields, frames in zip(self.leaf_fields_list, self._frames):
-            leaf_obs = reduce(getitem, fields, self.observation)
-            assert isinstance(leaf_obs, np.ndarray)
-            leaf_obs[:] = frames
-
-    def step(self,
-             action: ActT
-             ) -> Tuple[StackedObsType, SupportsFloat, bool, bool, InfoType]:
-        obs, reward, terminated, truncated, info = self.env.step(action)
-        self.refresh_observation(obs)
-        return self.observation, reward, terminated, truncated, info
-
-    def reset(self,
-              *,
-              seed: Optional[int] = None,
-              options: Optional[Dict[str, Any]] = None,
-              ) -> Tuple[StackedObsType, InfoType]:
-        observation, info = self.env.reset(seed=seed, options=options)
-        self._setup()
-        self.refresh_observation(observation)
-        return self.observation, info
+            nested_filter_keys = (tuple(env_observation_space.keys()),)
 
+        # Make sure all nested keys are stored in sequence
+        assert not isinstance(nested_filter_keys, str)
+        self.nested_filter_keys: Sequence[Sequence[Union[str, int]]] = []
+        for key_nested in nested_filter_keys:
+            if isinstance(key_nested, (str, int)):
+                key_nested = (key_nested,)
+            self.nested_filter_keys.append(tuple(key_nested))
 
-class StackedJiminyEnv(
-        BasePipelineWrapper[StackedObsType, ActT, ObsT, ActT],
-        Generic[ObsT, ActT]):
-    """ TODO: Write documentation.
-    """
-    def __init__(self,
-                 env: InterfaceJiminyEnv[ObsT, ActT],
-                 skip_frames_ratio: int = 0,
-                 **kwargs: Any) -> None:
-        """ TODO: Write documentation.
-        """
         # Backup some user argument(s)
+        self.num_stack = num_stack
         self.skip_frames_ratio = skip_frames_ratio
 
-        # Initialize some internal buffers
-        self.__n_last_stack = 0
+        # Get all paths associated with leaf values that must be stacked
+        self.path_filtered_leaves: Set[Tuple[Union[str, int], ...]] = set()
+        for path, _ in flatten_with_path(env.observation_space):
+            if any(path[:len(e)] == e for e in self.nested_filter_keys):
+                self.path_filtered_leaves.add(path)
+
+        # Make sure that some keys are preserved
+        if not self.path_filtered_leaves:
+            raise ValueError(
+                "At least one observation leaf must be stacked.")
 
-        # Instantiate wrapper
-        self.wrapper = PartialObservationStack(env, **kwargs)
+        # Initialize base class
+        super().__init__(env)
 
-        # Initialize base classes
-        super().__init__(env, **kwargs)
+        # Bind observation of the environment for all non-stacked keys
+        observation = copy(self.env.observation)
+        observation_leaves = dict(flatten_with_path(observation))
+        for path, space in flatten_with_path(self.observation_space):
+            if path not in self.path_filtered_leaves:
+                continue
+            observation_leaves[path] = zeros(space)
+        self.observation = unflatten_as(
+            observation, observation_leaves.values())
+
+        # Allocate fixed-length deque buffer for each leaf value to stack
+        self._frames_leaves: List[deque] = [
+            deque(maxlen=self.num_stack) for _ in self.path_filtered_leaves]
+
+        # Define frame update triplet for fast access
+        self._frames_update_triplets: Sequence[
+            Tuple[deque, np.ndarray, Tuple[np.ndarray, ...]]] = []
+        frames_iterator = iter(self._frames_leaves)
+        env_observation_leaves = flatten_with_path(env.observation)
+        for path, env_observation_leaf in env_observation_leaves:
+            if path not in self.path_filtered_leaves:
+                continue
+            assert isinstance(env_observation_leaf, np.ndarray)
+            frames = next(frames_iterator)
+            observation_leaf = observation_leaves[path]
+            if observation_leaf.ndim < 2:
+                observation_leaf = observation_leaf.reshape((-1, 1))
+            self._frames_update_triplets.append((
+                frames, env_observation_leaf, tuple(observation_leaf)))
 
-        # Bind the observation of the wrapper
-        self.observation = self.wrapper.observation
+        # Initialize some proxies for fast lookup
+        self._step_dt = self.env.step_dt
 
-        # Bind the action of the environment
-        assert self.action_space.contains(env.action)
-        self.action = env.action
+        # Number of stack update that has been skipped since the last one
+        self._n_last_stack = -1
+
+        # Whether the stack has been shifted to the left since last update
+        self._was_stack_shifted = True
 
     def _initialize_action_space(self) -> None:
+        """Configure the action space.
+        """
         self.action_space = self.env.action_space
 
     def _initialize_observation_space(self) -> None:
-        self.observation_space = self.wrapper.observation_space
+        # Define leaf observation spaces
+        observation_space_leaves = dict(
+            flatten_with_path(self.env.observation_space))
+        for path, space in observation_space_leaves.items():
+            # Skip leaf spaces that must not be stacked
+            if path not in self.path_filtered_leaves:
+                continue
+
+            # Make sure that stacked leaf spaces derive from `gym.spaces.Box`
+            if not (isinstance(space, gym.spaces.Box) and
+                    space.dtype is not None and
+                    issubclass(space.dtype.type, (np.floating, np.integer))):
+                raise TypeError(
+                    "Stacked leaf spaces must have type `gym.spaces.Box` "
+                    "whose dtype is either `np.floating` or `np.integer`.")
+
+            # Prepend the original bounds with an additional stacking dimension
+            low = np.repeat(space.low[np.newaxis], self.num_stack, axis=0)
+            high = np.repeat(space.high[np.newaxis], self.num_stack, axis=0)
+            observation_space_leaves[path] = gym.spaces.Box(
+                low=low, high=high, dtype=space.dtype.type)
+
+        # Define observation space by un-flattening leaf spaces
+        self.observation_space = unflatten_as(
+            self.env.observation_space, observation_space_leaves.values())
 
     def _setup(self) -> None:
         # Call base implementation
         super()._setup()
 
-        # Setup wrapper
-        self.wrapper._setup()
-
         # Make sure observe update is discrete-time
         if self.env.observe_dt <= 0.0:
             raise ValueError(
                 "This wrapper does not support time-continuous update.")
 
+        # Check if skip frame ratio is divisor of step update ratio
+        if self.skip_frames_ratio > 0:
+            step_ratio = round(self._step_dt / self.env.observe_dt)
+            frame_ratio = self.skip_frames_ratio + 1
+            if (step_ratio // frame_ratio) * frame_ratio != step_ratio:
+                LOGGER.warning(
+                    "Beware `step_dt // observe_dt` is not a multiple of "
+                    "`skip_frame_ratio + 1`.")
+
         # Copy observe and control update periods from wrapped environment
         self.observe_dt = self.env.observe_dt
         self.control_dt = self.env.control_dt
 
-        # Re-initialize some internal buffer(s).
+        # Reset frames to zero
+        frames_iterator = iter(self._frames_leaves)
+        for path, space in flatten_with_path(self.env.observation_space):
+            if path not in self.path_filtered_leaves:
+                continue
+            frames = next(frames_iterator)
+            for _ in range(self.num_stack):
+                frames.append(zeros(space))
+
+        # Re-initialize stack state.
         # Note that the initial observation is always stored.
-        self.__n_last_stack = self.skip_frames_ratio - 1
+        self._n_last_stack = self.skip_frames_ratio - 1
+        self._was_stack_shifted = True
 
     def refresh_observation(self, measurement: EngineObsType) -> None:
-        # Get environment observation
+        # Skip update if nothing to do
+        if not is_breakpoint(self.stepper_state.t, self.observe_dt, DT_EPS):
+            return
+
+        # Refresh environment observation
         self.env.refresh_observation(measurement)
 
-        # Update observed features if necessary
-        if self.is_simulation_running and is_breakpoint(
-                self.stepper_state.t, self.env.observe_dt, DT_EPS):
-            self.__n_last_stack += 1
-        if self.__n_last_stack == self.skip_frames_ratio:
-            self.__n_last_stack = -1
-            self.wrapper.refresh_observation(self.env.observation)
+        # Update stacked observation leaf values if necessary
+        update_stack, shift_stack = False, False
+        if self.is_simulation_running:
+            self._n_last_stack += 1
+            if self.skip_frames_ratio < 0:
+                if is_breakpoint(self.stepper_state.t, self._step_dt, DT_EPS):
+                    update_stack = True
+            elif self._n_last_stack == self.skip_frames_ratio:
+                update_stack = True
+            shift_stack = self._n_last_stack == 0
+
+        # Backup the nested observation fields to stack.
+        # Leaf values are copied to ensure they do not get altered later on.
+        for frames, env_obs_leaf, obs_leaf in self._frames_update_triplets:
+            if update_stack:
+                frames[-1] = env_obs_leaf.copy()
+            if shift_stack:
+                frames.append(env_obs_leaf)
+                multi_array_copyto(obs_leaf, tuple(frames))
+            else:
+                array_copyto(obs_leaf[-1], env_obs_leaf)
+
+        # Re-initialize number of skipped stack update
+        if update_stack:
+            self._n_last_stack = -1
+            self._was_stack_shifted = True
 
     def compute_command(self, action: ActT, command: np.ndarray) -> None:
         """Compute the motors efforts to apply on the robot.
 
         It simply forwards the command computed by the wrapped environment
         without any processing.
 
         :param action: High-level target to achieve by means of the command.
+        :param command: Lower-level command to updated in-place.
         """
         self.env.compute_command(action, command)
```

## Comparing `gym_jiminy-1.8.4.dist-info/METADATA` & `gym_jiminy-1.8.5.dist-info/METADATA`

 * *Files 17% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 Metadata-Version: 2.1
 Name: gym-jiminy
-Version: 1.8.4
+Version: 1.8.5
 Summary: Python-native OpenAI Gym interface between Jiminy open-source simulator and Reinforcement Learning frameworks.
 Home-page: https://github.com/duburcqa/jiminy
-Download-URL: https://github.com/duburcqa/jiminy/archive/1.8.4.tar.gz
+Download-URL: https://github.com/duburcqa/jiminy/archive/1.8.5.tar.gz
 Author: Alexis Duburcq
 Author-email: alexis.duburcq@gmail.com
 Maintainer: Alexis Duburcq
 License: MIT
 Keywords: reinforcement-learning robotics gym jiminy
 Classifier: Development Status :: 3 - Alpha
 Classifier: Intended Audience :: Science/Research
@@ -16,23 +16,23 @@
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Classifier: Programming Language :: Python :: 3.11
 Classifier: Programming Language :: Python :: 3.12
 Requires-Python: >=3.8,<3.13
-Requires-Dist: jiminy-py ~=1.8.4
+Requires-Dist: jiminy-py ~=1.8.5
 Requires-Dist: numpy
 Requires-Dist: numba >=0.54.0
 Requires-Dist: gymnasium <1.0,>=0.28
 Requires-Dist: typing-extensions
 Provides-Extra: all
-Requires-Dist: gym-jiminy-zoo ~=1.8.4 ; extra == 'all'
-Requires-Dist: gym-jiminy-rllib ~=1.8.4 ; extra == 'all'
-Requires-Dist: gym-jiminy-toolbox ~=1.8.4 ; extra == 'all'
+Requires-Dist: gym-jiminy-zoo ~=1.8.5 ; extra == 'all'
+Requires-Dist: gym-jiminy-rllib ~=1.8.5 ; extra == 'all'
+Requires-Dist: gym-jiminy-toolbox ~=1.8.5 ; extra == 'all'
 Provides-Extra: rllib
-Requires-Dist: gym-jiminy-rllib ~=1.8.4 ; extra == 'rllib'
+Requires-Dist: gym-jiminy-rllib ~=1.8.5 ; extra == 'rllib'
 Provides-Extra: toolbox
-Requires-Dist: gym-jiminy-toolbox ~=1.8.4 ; extra == 'toolbox'
+Requires-Dist: gym-jiminy-toolbox ~=1.8.5 ; extra == 'toolbox'
 Provides-Extra: zoo
-Requires-Dist: gym-jiminy-zoo ~=1.8.4 ; extra == 'zoo'
+Requires-Dist: gym-jiminy-zoo ~=1.8.5 ; extra == 'zoo'
```

## Comparing `gym_jiminy-1.8.4.dist-info/RECORD` & `gym_jiminy-1.8.5.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -1,35 +1,35 @@
 gym_jiminy/common/__init__.py,sha256=8BemhrCxALdOEEKFpFRutfsu4t2guZIMIIpjx0bIU08,230
 gym_jiminy/common/py.typed,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-gym_jiminy/common/bases/__init__.py,sha256=RZQ8V3sEuFqAv3hiNE71FklTWTfAU6cXi57To6fo2Eg,1495
+gym_jiminy/common/bases/__init__.py,sha256=BIqho7mjwOk7wLawJHh38NCa64dMJiKwo2mAQEgaQQo,1548
 gym_jiminy/common/bases/blocks.py,sha256=jYyInWm3d2LWrBDmO1wh2TsTnrzJ1lYANIdpPlxoURw,10466
-gym_jiminy/common/bases/interfaces.py,sha256=yXvuXZDSi3HBo51EG-SVd_drMMNiq59ZZqsk4Ls7XSM,14577
-gym_jiminy/common/bases/pipeline.py,sha256=KWt2hGT6gsl3qSI0IhpF1kzFl2Ya1Yrdp_Mgbho7Qmg,40682
+gym_jiminy/common/bases/interfaces.py,sha256=atMhcFbqAo9EJPOddv_mIfzPhj2nvuUy40Y7aikUG80,14953
+gym_jiminy/common/bases/pipeline.py,sha256=X2RlAWyUpuoXM8_29ob0oThj5HSfecW0kpbprDPCxb0,40957
 gym_jiminy/common/bases/quantity.py,sha256=HWSSByxc1RPQReCZqTgQi2pQpOcUBBH1jduwPdiPraY,18035
 gym_jiminy/common/blocks/__init__.py,sha256=zpuD5GgmxEUAAWih0H-Zwy_JF8BlouStEAAPKQ5koWc,385
 gym_jiminy/common/blocks/deformation_estimator.py,sha256=1T1ZAvaqOdwl6mKQ3jZ0jFxgQ7SWQnT3sP56GWl2ekY,37430
 gym_jiminy/common/blocks/mahony_filter.py,sha256=3JwBb1ushRwOXKPvbitbYVlqwU-Pooth-sgCJQbJvoY,17212
 gym_jiminy/common/blocks/motor_safety_limit.py,sha256=3H_6gzkXTbM-nYyTYiVh3I4BP25DXFKci6dhXMNd0EA,10089
-gym_jiminy/common/blocks/proportional_derivative_controller.py,sha256=fQN0XUvBXdDgJpLMHxMs0TEqtmkE3oNSc84v5nid-oI,26392
+gym_jiminy/common/blocks/proportional_derivative_controller.py,sha256=o6NYJ3C5jTgBu9nG4RgQTXrK-bALsaMBUbG8VP3GpyQ,26459
 gym_jiminy/common/envs/__init__.py,sha256=A5GYVURVmtE_IIPZfBliGhvfwSvifbZmkNWlLClRUO4,178
-gym_jiminy/common/envs/generic.py,sha256=jWXuImtGi8JqGG90GBV-SMNyhND5eowWo5Br2FIoeX8,69411
+gym_jiminy/common/envs/generic.py,sha256=e3YgGmkfdNy49mGBk3JDKGv34-F4-m-iXElfQ2N2EQ0,70853
 gym_jiminy/common/envs/locomotion.py,sha256=iU2-3bYCtGV70QxymSESW99oD-bHIvv8Q8UDKv9yO4w,18748
 gym_jiminy/common/envs/internal/__init__.py,sha256=TKkRy9iC7oL2yPlYzQBPXeJ5h7yEVbJlOfR2-ZKkcKw,118
 gym_jiminy/common/envs/internal/play.py,sha256=Rh87t2tL4HzpON0fihDwxYIMEK-w5xWjoVi_VYwsFsI,9350
 gym_jiminy/common/quantities/__init__.py,sha256=YtyCZAotxhOJzwFKyXvlKIbJteTLgvvtqIfIuxtUS6E,367
-gym_jiminy/common/quantities/generic.py,sha256=aIn-mHJEmAuai75SeSM2yt7_3VxBdBxu62Hw9PNW-iU,11600
+gym_jiminy/common/quantities/generic.py,sha256=xItEGZubWW2s4tNEwh35SBBHQGbqZ_dFBwbU02y-XrQ,11998
 gym_jiminy/common/quantities/locomotion.py,sha256=7LV4FiJ978gdK7TGV7VR-B02vBTkOrwXYvl8TD3Ma0k,4496
 gym_jiminy/common/quantities/manager.py,sha256=AG7BGubkqaIq1uEqF6qfXdG3CSVv4S31MdFXVnqADBo,7024
-gym_jiminy/common/utils/__init__.py,sha256=3i9o-zWgW24CWIDEwoT6BVj8hEUFZ_vEWBmiqriNggc,2263
+gym_jiminy/common/utils/__init__.py,sha256=4ZPCvwPQODSDf_4Xq-uFlTgH-Uq4wfHMqHtldDX3cUo,2318
 gym_jiminy/common/utils/math.py,sha256=XjP4Gx1CGqfmjPaeEBCje_lUXs65_s6bJcDgGmKTWfQ,21000
-gym_jiminy/common/utils/misc.py,sha256=-om0HJumO-7aj3XayVSgDTNwG9-o-TmuY5ZZk5_TpX4,8972
+gym_jiminy/common/utils/misc.py,sha256=R9awz80KH3BoXzifTmmQ0evB2GQbbnAsHHwaDuNfdGk,8920
 gym_jiminy/common/utils/pipeline.py,sha256=Zf8WlE3nux5rt7c-OQ6-4taMSj5f-81q3J-fM1u1u_o,10189
-gym_jiminy/common/utils/spaces.py,sha256=A5-_tuNr7wdY7XxEIhmP5agGbUZ5VZNVSskG_EIzj_o,53495
-gym_jiminy/common/wrappers/__init__.py,sha256=vdX9DeoMfipj4XDVuG7muM6uXo3YZrIGb-d9Lfr3-ys,477
-gym_jiminy/common/wrappers/flatten.py,sha256=5lsmOdTE3hZCJMRNcHGQOnsrBI6I05Hb1ESpbKqqxxA,6115
+gym_jiminy/common/utils/spaces.py,sha256=nvCRfl4p6bCKIFi4DdY1N3jMqud9Etzn939aXDJCwi8,54010
+gym_jiminy/common/wrappers/__init__.py,sha256=6azq0upqUnzeW2ejJ4OB2yGcUFZDWY-ggMUtQDhZz4I,421
+gym_jiminy/common/wrappers/flatten.py,sha256=kWvJlyvmswsA6Uv94oJ5c3zNRT5bXR7wdM1yuUWUzsQ,6153
 gym_jiminy/common/wrappers/normalize.py,sha256=TD3SnkMDydC2688ozpnNR7Y2_BIOEYcAIa6OtSb11B8,4039
-gym_jiminy/common/wrappers/observation_filter.py,sha256=qYrRM8eKV7HJ1_-CWwuUauTVTf8TalHq2JsBaHrQdPQ,3747
-gym_jiminy/common/wrappers/observation_stack.py,sha256=9rUAi-ZGI8pLF2niK2A06-VmvLe7GDuUwlhwhe-H7H8,10626
-gym_jiminy-1.8.4.dist-info/METADATA,sha256=BrG6uFOcL8cohu21Q0ICYqEenAULNnKNDBayR4-QVII,1605
-gym_jiminy-1.8.4.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
-gym_jiminy-1.8.4.dist-info/top_level.txt,sha256=c6Ipde11Sivat1D9sNj6sn3TCpadD0Qqk9fMzWYQLko,11
-gym_jiminy-1.8.4.dist-info/RECORD,,
+gym_jiminy/common/wrappers/observation_filter.py,sha256=UTQ2WhOdmsFleY6W9nhd9G4oKYUv7xj5U-ThP3juhMg,7770
+gym_jiminy/common/wrappers/observation_stack.py,sha256=1TswIefJ5N5JXRmkyyeTZ0NbBGHSBvpvzQh7xfK0F1s,10955
+gym_jiminy-1.8.5.dist-info/METADATA,sha256=pTbM0CtebY29Z0yyKUkdEhAh3OJyS0AeRIBbGEzLJ34,1605
+gym_jiminy-1.8.5.dist-info/WHEEL,sha256=GJ7t_kWBFywbagK5eo9IoUwLW6oyOeTKmQ-9iHFVNxQ,92
+gym_jiminy-1.8.5.dist-info/top_level.txt,sha256=c6Ipde11Sivat1D9sNj6sn3TCpadD0Qqk9fMzWYQLko,11
+gym_jiminy-1.8.5.dist-info/RECORD,,
```


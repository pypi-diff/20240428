# Comparing `tmp/pybioos-0.0.6-py3-none-any.whl.zip` & `tmp/pybioos-0.0.7-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,24 +1,24 @@
-Zip file size: 41693 bytes, number of entries: 38
--rw-r--r--  2.0 unx       56 b- defN 24-Apr-23 02:23 bioos/__about__.py
+Zip file size: 42390 bytes, number of entries: 38
+-rw-r--r--  2.0 unx       56 b- defN 24-Apr-28 12:27 bioos/__about__.py
 -rw-r--r--  2.0 unx       22 b- defN 24-Jan-24 08:50 bioos/__init__.py
 -rw-r--r--  2.0 unx     2409 b- defN 24-Jan-24 01:29 bioos/bioos.py
--rw-r--r--  2.0 unx    10266 b- defN 24-Apr-23 02:24 bioos/bioos_workflow.py
+-rw-r--r--  2.0 unx    14122 b- defN 24-Apr-28 12:26 bioos/bioos_workflow.py
 -rw-r--r--  2.0 unx     4307 b- defN 24-Jan-27 02:29 bioos/config.py
 -rw-r--r--  2.0 unx     2459 b- defN 24-Jan-24 01:59 bioos/errors.py
 -rw-r--r--  2.0 unx     3204 b- defN 24-Jan-24 01:59 bioos/log.py
 -rw-r--r--  2.0 unx        1 b- defN 24-Jan-24 02:00 bioos/internal/__init__.py
 -rw-r--r--  2.0 unx    12264 b- defN 24-Jan-29 07:18 bioos/internal/tos.py
 -rw-r--r--  2.0 unx        1 b- defN 24-Jan-24 01:59 bioos/models/__init__.py
 -rw-r--r--  2.0 unx      391 b- defN 24-Jan-24 02:00 bioos/models/models.py
 -rw-r--r--  2.0 unx        1 b- defN 24-Jan-24 01:59 bioos/resource/__init__.py
 -rw-r--r--  2.0 unx     5089 b- defN 24-Jan-24 01:59 bioos/resource/data_models.py
 -rw-r--r--  2.0 unx     8281 b- defN 24-Jan-29 06:48 bioos/resource/files.py
 -rw-r--r--  2.0 unx     1300 b- defN 24-Jan-24 01:59 bioos/resource/utility.py
--rw-r--r--  2.0 unx    19541 b- defN 24-Mar-19 02:53 bioos/resource/workflows.py
+-rw-r--r--  2.0 unx    19724 b- defN 24-Apr-28 12:25 bioos/resource/workflows.py
 -rw-r--r--  2.0 unx     3995 b- defN 24-Jan-24 01:59 bioos/resource/workspaces.py
 -rw-r--r--  2.0 unx     6724 b- defN 24-Jan-24 01:59 bioos/service/BioOsService.py
 -rw-r--r--  2.0 unx        1 b- defN 24-Jan-24 01:59 bioos/service/__init__.py
 -rw-r--r--  2.0 unx     8737 b- defN 24-Jan-24 01:59 bioos/service/api.py
 -rw-r--r--  2.0 unx     1009 b- defN 24-Jan-24 01:59 bioos/service/config.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-23 04:12 bioos/tests/__init__.py
 -rw-r--r--  2.0 unx      606 b- defN 24-Jan-23 04:12 bioos/tests/base.py
@@ -27,14 +27,14 @@
 -rw-r--r--  2.0 unx     6926 b- defN 24-Jan-23 04:12 bioos/tests/files.py
 -rw-r--r--  2.0 unx     1472 b- defN 24-Jan-23 04:12 bioos/tests/utils.py
 -rw-r--r--  2.0 unx    14557 b- defN 24-Jan-23 04:12 bioos/tests/workflows.py
 -rw-r--r--  2.0 unx     5229 b- defN 24-Jan-23 04:12 bioos/tests/workspaces.py
 -rw-r--r--  2.0 unx        0 b- defN 24-Jan-23 04:12 bioos/utils/__init__.py
 -rw-r--r--  2.0 unx     1651 b- defN 24-Jan-26 06:12 bioos/utils/common_tools.py
 -rw-r--r--  2.0 unx      133 b- defN 24-Jan-23 04:12 bioos/utils/workflows.py
--rw-r--r--  2.0 unx     1063 b- defN 24-Apr-23 03:02 pybioos-0.0.6.dist-info/LICENSE
--rw-r--r--  2.0 unx      770 b- defN 24-Apr-23 03:02 pybioos-0.0.6.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 24-Apr-23 03:02 pybioos-0.0.6.dist-info/WHEEL
--rw-r--r--  2.0 unx       59 b- defN 24-Apr-23 03:02 pybioos-0.0.6.dist-info/entry_points.txt
--rw-r--r--  2.0 unx        6 b- defN 24-Apr-23 03:02 pybioos-0.0.6.dist-info/top_level.txt
--rw-rw-r--  2.0 unx     2996 b- defN 24-Apr-23 03:02 pybioos-0.0.6.dist-info/RECORD
-38 files, 141095 bytes uncompressed, 36959 bytes compressed:  73.8%
+-rw-r--r--  2.0 unx     1063 b- defN 24-Apr-28 12:40 pybioos-0.0.7.dist-info/LICENSE
+-rw-r--r--  2.0 unx      770 b- defN 24-Apr-28 12:40 pybioos-0.0.7.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 24-Apr-28 12:40 pybioos-0.0.7.dist-info/WHEEL
+-rw-r--r--  2.0 unx       59 b- defN 24-Apr-28 12:40 pybioos-0.0.7.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx        6 b- defN 24-Apr-28 12:40 pybioos-0.0.7.dist-info/top_level.txt
+-rw-rw-r--  2.0 unx     2996 b- defN 24-Apr-28 12:40 pybioos-0.0.7.dist-info/RECORD
+38 files, 145134 bytes uncompressed, 37656 bytes compressed:  74.1%
```

## zipnote {}

```diff
@@ -90,26 +90,26 @@
 
 Filename: bioos/utils/common_tools.py
 Comment: 
 
 Filename: bioos/utils/workflows.py
 Comment: 
 
-Filename: pybioos-0.0.6.dist-info/LICENSE
+Filename: pybioos-0.0.7.dist-info/LICENSE
 Comment: 
 
-Filename: pybioos-0.0.6.dist-info/METADATA
+Filename: pybioos-0.0.7.dist-info/METADATA
 Comment: 
 
-Filename: pybioos-0.0.6.dist-info/WHEEL
+Filename: pybioos-0.0.7.dist-info/WHEEL
 Comment: 
 
-Filename: pybioos-0.0.6.dist-info/entry_points.txt
+Filename: pybioos-0.0.7.dist-info/entry_points.txt
 Comment: 
 
-Filename: pybioos-0.0.6.dist-info/top_level.txt
+Filename: pybioos-0.0.7.dist-info/top_level.txt
 Comment: 
 
-Filename: pybioos-0.0.6.dist-info/RECORD
+Filename: pybioos-0.0.7.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## bioos/__about__.py

```diff
@@ -1,4 +1,4 @@
 # coding:utf-8
 
 # Package version
-__version__ = "0.0.6"
+__version__ = "0.0.7"
```

## bioos/bioos_workflow.py

```diff
@@ -1,17 +1,18 @@
 import argparse
 import json
 import logging
 import os
+import re
 import time
 
 import pandas as pd
 
 from bioos import bioos
-from bioos.errors import NotFoundError
+from bioos.errors import NotFoundError, ParameterError
 
 
 def recognize_files_from_input_json(workflow_input_json: dict) -> dict:
     putative_files = {}
 
     # this version only support absolute path
 
@@ -155,14 +156,108 @@
             "submission_desc": submission_desc,
             "call_caching": call_caching,
         }
         self.logger.info("Build submission params successfully.")
 
         return self.params_submit
 
+    def preprocess2(self,
+                    input_json_file: str,
+                    data_model_name: str = "dm",
+                    submission_desc: str = "Submit by pybioos",
+                    call_caching: bool = True,
+                    force_reupload: bool = False):
+        if not os.path.isfile(input_json_file):
+            raise ParameterError('Input_json_file is not found.')
+
+        input_json = json.load(open(input_json_file))
+        self.logger.info("Load json input successfully.")
+
+        # putative files
+        input_json_str = json.dumps(input_json)
+
+        # capture strings containing "/" the test if the file exists
+        putative_files = [
+            s.strip('"\'') for s in re.findall(
+                r'''"[-_\w./:]+?/[-_\w./:]+?"''', input_json_str)
+            if os.path.isfile(s.strip('"\''))
+        ]
+
+        putative_files = set(putative_files)
+        file_str = ''
+        for putative_file in putative_files:
+            file_str = file_str + '\t' + putative_file + '\n'
+
+        self.logger.info(
+            f"Putative files need to upload includes:\n{file_str}")
+
+        # provision upload and file path replace
+        df = self.ws.files.list('input_provision')
+        uploaded_files = [] if df.empty else df.key.to_list()
+        for putative_file in putative_files:
+            target = f"input_provision/{os.path.basename(putative_file)}"
+
+            if not force_reupload and target in uploaded_files:
+                self.logger.info(
+                    f"Skip target site already existed file {putative_file}.")
+            else:
+                self.logger.info(f"Start upload {putative_file}.")
+                self.ws.files.upload(putative_file,
+                                     target="input_provision/",
+                                     flatten=True)
+                self.logger.info(f"Finish upload {putative_file}.")
+            s3_location = self.ws.files.s3_urls(target)[0]
+            input_json_str = re.sub(putative_file, s3_location, input_json_str)
+
+        # start build params_submit
+        self.params_submit = {
+            "outputs": "{}",
+            "submission_desc": submission_desc,
+            "call_caching": call_caching,
+        }
+
+        # if the input json is a batch or singleton submission
+        input_json = json.loads(input_json_str)
+        if isinstance(input_json, list):  # batch mode
+            self.logger.info("Batch mode found.")
+
+            # build data model for batch mode
+            inputs_list = input_json
+            df = pd.DataFrame(inputs_list)
+            id_col = f"{data_model_name}_id"
+            columns = [
+                id_col,
+            ]
+            columns.extend(df.columns)
+            df[id_col] = [f"tmp_{x}" for x in list(range(len(df)))]
+            df = df.reindex(columns=columns)
+            columns = [key.split(".")[-1] for key in df.columns.to_list()]
+            df.columns = pd.Index(columns)
+
+            # write data models
+            self.ws.data_models.write({data_model_name: df.map(str)},
+                                      force=True)
+            self.logger.info("Set data model successfully.")
+
+            # match the batch sytax of Bio-OS
+            unupdate_dict = inputs_list[0]
+            for key, _ in unupdate_dict.items():
+                unupdate_dict[key] = f'this.{key.split(".")[-1]}'
+
+            self.params_submit["inputs"] = json.dumps(unupdate_dict)
+            self.params_submit["data_model_name"] = data_model_name
+            self.params_submit["row_ids"] = df[id_col].to_list()
+
+        else:  # singleton mode
+            self.logger.info("Singleton mode found.")
+            self.params_submit["inputs"] = json.dumps(input_json)
+
+        self.logger.info("Build params dict successfully.")
+        return self.params_submit
+
     def postprocess(self, download=False):
         # 假设全部执行完毕
         #  对运行完成的目录进行下载
         # 证实bioos包只能对文件的list进行下载，不支持文件夹
         # ws.files.list方法不能指定起始路径，需要改进
         # 需要有一个地方执行定时任务，对run的status进行查询，并记录状态，对每次新完成的run进行后处理
         files = []
@@ -262,19 +357,19 @@
 
     # login and submit
     bioos.login(endpoint=parsed_args.endpoint,
                 access_key=parsed_args.ak,
                 secret_key=parsed_args.sk)
     bw = Bioos_workflow(workspace_name=parsed_args.workspace_name,
                         workflow_name=parsed_args.workflow_name)
-    bw.preprocess(input_json_file=parsed_args.input_json,
-                  data_model_name=parsed_args.data_model_name,
-                  submission_desc=parsed_args.submission_desc,
-                  call_caching=parsed_args.call_caching,
-                  force_reupload=parsed_args.force_reupload)
+    bw.preprocess2(input_json_file=parsed_args.input_json,
+                   data_model_name=parsed_args.data_model_name,
+                   submission_desc=parsed_args.submission_desc,
+                   call_caching=parsed_args.call_caching,
+                   force_reupload=parsed_args.force_reupload)
     bw.submit_workflow_bioosapi()
 
     # moniter
     def all_runs_done() -> bool:
 
         statuses = []
         for run in bw.runs:
```

## bioos/resource/workflows.py

```diff
@@ -288,18 +288,19 @@
                 data_entity_row_ids.add(run.get("DataEntityRowID"))
         self.data_model_rows = list(data_entity_row_ids)
         # get data model name by call list data models
         models = Config.service().list_data_models({
             'WorkspaceID':
             self.workspace_id,
         }).get("Items")
-        for model in models:
-            if model["ID"] == item["DataModelID"]:
-                self.data_model = model.get("Name")
-                break
+        if "DataModelID" in item.keys():
+            for model in models:
+                if model["ID"] == item["DataModelID"]:
+                    self.data_model = model.get("Name")
+                    break
 
         self.call_cache = item.get("ExposedOptions").get("ReadFromCache")
         self.outputs = item.get("Outputs")
         self.inputs = item.get("Inputs")
         self.owner = item.get("OwnerName")
         self.name = item.get("Name")
         self.description = item.get("Description")
@@ -509,17 +510,22 @@
         """
         res = DataModelResource(self.workspace_id).list(). \
             query(f"Name=='{name}'")
         if res.empty:
             return ""
         return res["ID"].iloc[0]
 
-    def submit(self, data_model_name: str, row_ids: List[str], inputs: str, outputs: str,
-               submission_desc: str, call_caching: bool, submission_name_suffix: str = "") \
-            -> List[Run]:
+    def submit(self,
+               inputs: str,
+               outputs: str,
+               submission_desc: str,
+               call_caching: bool,
+               submission_name_suffix: str = "",
+               row_ids: List[str] = [],
+               data_model_name: str = '') -> List[Run]:
         """Submit an existed workflow.
 
         *Example*:
         ::
 
             ws = bioos.workspace("foo")
             wf = ws.workflow(name="123456788")
@@ -543,48 +549,44 @@
         :param submission_desc: The description of this submission
         :type submission_desc: str
         :param call_caching: CallCaching searches in the cache of previously running tasks with exactly the same commands and exactly the same input tasks. If the cache hit, the results of the previous task will be used instead of reorganizing, thereby saving time and resources.
         :type call_caching: bool
         :return: Result Runs corresponding to submitted workflows
         :rtype: List[Run]
         """
-        if not row_ids:
-            raise ParameterError("row_ids")
+
         if not inputs and not is_json(inputs):
             raise ParameterError('inputs')
         if not outputs and not is_json(outputs):
             raise ParameterError('outputs')
-
-        data_model_id = self.query_data_model_id(data_model_name)
-        if not data_model_id:
-            raise ParameterError("data_model_name")
-
         if not submission_name_suffix:
             submission_name_suffix = datetime.now().strftime(
                 '%Y-%m-%d-%H-%M-%S')
-        submission_id = Config.service().create_submission({
-            "ClusterID":
-            self.get_cluster,
-            'WorkspaceID':
-            self.workspace_id,
-            'WorkflowID':
-            self.id,
-            'Name':
-            workflows.submission_name(self.name, submission_name_suffix),
-            'Description':
-            submission_desc,
-            'DataModelID':
-            data_model_id,
-            'DataModelRowIDs':
-            row_ids,
-            'Inputs':
-            inputs,
+
+        params = {
+            "ClusterID": self.get_cluster,
+            'WorkspaceID': self.workspace_id,
+            'WorkflowID': self.id,
+            'Name': workflows.submission_name(self.name,
+                                              submission_name_suffix),
+            'Description': submission_desc,
+            'Inputs': inputs,
             'ExposedOptions': {
                 "ReadFromCache": call_caching,
                 # TODO this may change in the future
                 "ExecutionRootDir": f"s3://{self.bucket}"
             },
-            'Outputs':
-            outputs,
-        }).get("ID")
+            'Outputs': outputs,
+        }
+
+        # It is batch mode when data_model_name and row_ids are specified.
+        if data_model_name and row_ids:
+            data_model_id = self.query_data_model_id(data_model_name)
+            if not data_model_id:
+                raise ParameterError("data_model_name")
+
+            params['DataModelID'] = data_model_id
+            params['DataModelRowIDs'] = row_ids
+
+        submission_id = Config.service().create_submission(params).get("ID")
 
         return Submission(self.workspace_id, submission_id).runs
```

## Comparing `pybioos-0.0.6.dist-info/LICENSE` & `pybioos-0.0.7.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `pybioos-0.0.6.dist-info/METADATA` & `pybioos-0.0.7.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: pybioos
-Version: 0.0.6
+Version: 0.0.7
 Summary: BioOS SDK for Python
 Home-page: https://github.com/GBA-BI/pybioos
 Author: Jilong Liu
 Author-email: liu_jilong@gzlab.ac.cn
 License: MIT Licence
 Keywords: pip,bioos
 Platform: any
```

## Comparing `pybioos-0.0.6.dist-info/RECORD` & `pybioos-0.0.7.dist-info/RECORD`

 * *Files 7% similar despite different names*

```diff
@@ -1,23 +1,23 @@
-bioos/__about__.py,sha256=6c7X3ThTtu9hGlmyqd4INLPcK6ABrCwlVEd7i0BVvAw,56
+bioos/__about__.py,sha256=okNssbP5M6Wx_3bJKWb7uNW9yTV_ylNEEhx1uaNcEAc,56
 bioos/__init__.py,sha256=4GZKi13lDTD25YBkGakhZyEQZWTER_OWQMNPoH_UM2c,22
 bioos/bioos.py,sha256=fHzOb1l5wYxw6NVYYZDiFcgk4V28BAgWEc3ev12reWs,2409
-bioos/bioos_workflow.py,sha256=MC3Bbu7t-sT7bTFd5hZaObNVctm_IBCoDBphv6kdRS8,10266
+bioos/bioos_workflow.py,sha256=ZhlgIqsCMUBnNvzW1hQIlagJtZpSeDVFp99yXpIU358,14122
 bioos/config.py,sha256=CvFabYqV1BkFWO8fnr5vBf6xNtNzA8hAEVeEIbvAOm8,4307
 bioos/errors.py,sha256=Lzz2rkjDOTR2X9CnVkmsmqeOgmNqbi46WAxnC6LEGm0,2459
 bioos/log.py,sha256=twiCvf5IgJB7uvzANwBluSlztJN8ZrxbGZUBGlZ0vps,3204
 bioos/internal/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 bioos/internal/tos.py,sha256=0R6YN2lxjjZsuMfv0yLSkBmz_LqmzQGb8GagnUMc8EY,12264
 bioos/models/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 bioos/models/models.py,sha256=HPCLZ4jK2HDth4vrlVHba21CiW6y7y5im1kOjV4adc8,391
 bioos/resource/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 bioos/resource/data_models.py,sha256=enKp8yyQI8IbRqe--0Xtyg1XzOwQQPQzoQsx_hNuZ6E,5089
 bioos/resource/files.py,sha256=zMxsLg1CfZyrgvMesphMz-qROU-38fE_E8XtN9DlWtE,8281
 bioos/resource/utility.py,sha256=emY7qVLLLvGmQYlVj-_bLAxU7i1GfQOUybdRkfEDwVA,1300
-bioos/resource/workflows.py,sha256=06e9KS3Bm73mh9U6cDI7g8TmReM62EcgIjAxPGaqXaw,19541
+bioos/resource/workflows.py,sha256=A-fEUqPGuCmqZNNaW1zc8cozFJoQcg8bzXSyI2ZLypM,19724
 bioos/resource/workspaces.py,sha256=Gmr8y_sjK7TQbhMhQ_7rxqR1KFcwU72I95YYCFrrLBQ,3995
 bioos/service/BioOsService.py,sha256=HuYUEwomHCLpA1MYgVqGyWAQWHM-_BHB-jmy9VsOlnQ,6724
 bioos/service/__init__.py,sha256=AbpHGcgLb-kRsJGnwFEktk7uzpZOCcBY74-YBdrKVGs,1
 bioos/service/api.py,sha256=Khihn187bACEfBcJ-tRS9JO29-VCBsH0-9qq-i5WxkQ,8737
 bioos/service/config.py,sha256=FbBsb6CpcLsQZH7n8uuUbFVhkpqYOEnOe0xGkA7ZrjA,1009
 bioos/tests/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 bioos/tests/base.py,sha256=B7jSiMTkSN0wv1oVqtwlW8QuKMbrmEIZgXH1jxx1EsU,606
@@ -26,13 +26,13 @@
 bioos/tests/files.py,sha256=YgT0N1VdvmFVldtdqepAUkJQvEeuw_g3Ft9wul1rs2c,6926
 bioos/tests/utils.py,sha256=PZ4e1AtU4Mt5Z8eSC1vda26pPE2ODghhAmICOlkl550,1472
 bioos/tests/workflows.py,sha256=N70oWeSb8-7UcDqVP7e6oJ2QyDG1beA6_GWQy7EOyNo,14557
 bioos/tests/workspaces.py,sha256=LuuRrTs2XqfE5mGQyJNl9RBtuMb4NZHBJFoO8HMZVYQ,5229
 bioos/utils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 bioos/utils/common_tools.py,sha256=fgMoE_-qZjgfQtUj_pmCTyYDtbJasyfH4Gm3VQsbgBQ,1651
 bioos/utils/workflows.py,sha256=zRbwTUigoM5V5LFOgzQPm3kwxt5Ogz95OFfefJc6Fjo,133
-pybioos-0.0.6.dist-info/LICENSE,sha256=cPkGXsgfPgEhIns7Lt3Avxx0Uy-VbdsoP8jvNGuj3cE,1063
-pybioos-0.0.6.dist-info/METADATA,sha256=nAXmL2xb2kkLiBNi93ex3efK-381AcVuvb6RdyfzWrk,770
-pybioos-0.0.6.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
-pybioos-0.0.6.dist-info/entry_points.txt,sha256=8TRx1zyu7ja3x5RNaeFxeiYTj_-tiWydbuSulxi3TM0,59
-pybioos-0.0.6.dist-info/top_level.txt,sha256=llpzydkKVDSaWZgz3bsTUsQmhoQpc_JcRJg2-H-5a2U,6
-pybioos-0.0.6.dist-info/RECORD,,
+pybioos-0.0.7.dist-info/LICENSE,sha256=cPkGXsgfPgEhIns7Lt3Avxx0Uy-VbdsoP8jvNGuj3cE,1063
+pybioos-0.0.7.dist-info/METADATA,sha256=a-HFZWmOAZg1U9jIc5v2I-1mh7hJHA25pZbEeU3uPu8,770
+pybioos-0.0.7.dist-info/WHEEL,sha256=oiQVh_5PnQM0E3gPdiz09WCNmwiHDMaGer_elqB3coM,92
+pybioos-0.0.7.dist-info/entry_points.txt,sha256=8TRx1zyu7ja3x5RNaeFxeiYTj_-tiWydbuSulxi3TM0,59
+pybioos-0.0.7.dist-info/top_level.txt,sha256=llpzydkKVDSaWZgz3bsTUsQmhoQpc_JcRJg2-H-5a2U,6
+pybioos-0.0.7.dist-info/RECORD,,
```

